---
title: "Traffic, Land Use, and Wildlife-Vehicle Collisions in Denmark"
description: "Using a hurdle model to understand roadkill patterns on Danish roads"
date: 2025-11-29
categories: [MEDS, R, Statistics, Wildlife]
image: eds222-final-cover.jpg
citation:
  url: https://rellimylime.github.io/posts/eds222-final/
bibliography: references.bib
output: 
  html_document:
    code_download: true
execute:
  eval: true
  echo: true
  warning: false
  message: false
---

# 1. Introduction: Why This Matters

Wildlife-vehicle collisions threaten biodiversity and pose safety risks. Understanding which road and landscape characteristics predict roadkill hotspots enables evidence-based mitigation. We analyze \~11,000 roadkill events on 241,000 Danish road segments (2017-2019) to test whether traffic volume, forest proximity, and urban development predict collision rates.

**The puzzle**: Some roads experience frequent wildlife collisions while others have zero incidents. Is it just random chance or collection bias? Or are there systematic patterns we can identify and address?

If we can predict which roads are most likely to become collision hotspots, transportation planners and conservationists can install wildlife crossings, implement warning systems, or adjust speed limits in high-risk areas.

### **Research Question**

**How do traffic volume and land use characteristics affect wildlife-vehicle collisions on Danish roads?**

Specifically, we investigate two processes:

1.  **Occurrence**: What makes roadkill more likely to happen at all on a given road segment?
2.  **Intensity**: Once roadkill does occur, what factors influence how many collision events happen?

The high proportion of road segments with zero observed roadkill (\~83%) suggests these processes operate differently, making a hurdle model the appropriate statistical framework.

# 2. Building a Theory: What Causes Roadkill?

### **The Causal Story**

Imagine you're a deer deciding whether to cross a road. Several factors affect your collision risk:

1.  **Traffic volume**: More vehicles = more chances for collision
2.  **Your habitat**: You're more likely to be near roads that pass through forests or parks
3.  **Road characteristics**: Wider, faster roads are harder to cross safely
4.  **Human development**: You avoid heavily urbanized areas

### **Visualizing Causal Relationships: The DAG**

Now, let's formalize our deer's decision-making process with a Directed Acyclic Graph (DAG).

```{r}
#| label: aesthetics
#| include: false

# Define colors to match my website
primary_color <- "#2A9D8F"
accent_color <- "#E76F51"
neutral_color <- "#6A4C93"
text_dark <- "#2B2D42"
text_mid <- "#5A5A5A"
bg_warm <- "#FFFEF9"
backup_color <- "#E9C46A"
# DAG libraries
library(ggdag)
library(dagitty)
library(tidyverse)

# Unified theme for all plots
theme_cohesive <- function() {
  theme_minimal() +
    theme(
      text = element_text(color = text_dark),
      plot.title = element_text(size = 14, face = "bold", color = text_dark),
      plot.subtitle = element_text(size = 11, color = text_mid),
      plot.background = element_rect(fill = bg_warm, color = NA),
      panel.background = element_rect(fill = bg_warm, color = NA),
      panel.grid.major = element_line(color = "#E5E5E5", linewidth = 0.3),
      panel.grid.minor = element_blank(),
      axis.text = element_text(color = text_mid),
      axis.title = element_text(color = text_dark, face = "bold")
    )
}

```

```{r}
#| label: dag
#| fig-width: 8
#| fig-height: 6
#| echo: false

# Define DAG
roadkill_dag <- dagify(
  Roadkill ~ Traffic + LandUse + RoadType + Speed,
  Traffic ~ RoadType + LandUse,
  Speed ~ RoadType,
  RoadType ~ LandUse,
  outcome = "Roadkill",
  labels = c(
    "Roadkill" = "Roadkill",
    "Traffic" = "Traffic\nVolume",
    "LandUse" = "Land\nUse",
    "RoadType" = "Road\nType",
    "Speed" = "Speed\nLimit"
  ),
  coords = list(
    x = c(Traffic = 1, RoadType = 1, Speed = 2, LandUse = 2, Roadkill = 3),
    y = c(Traffic = 2, RoadType = 1, Speed = 1, LandUse = 2, Roadkill = 1.5)
  )
)

# Prepare for plotting with labels
dag_tidy <- roadkill_dag %>% 
  tidy_dagitty() %>%
  mutate(
    color_group = case_when(
      name == "Roadkill" ~ "outcome",
      TRUE ~ "other"
    )
  )

# Plot with custom styling
ggplot(dag_tidy, aes(x = x, y = y, xend = xend, yend = yend)) +
  # Edges
  geom_dag_edges(
    edge_width = 0.8,
    arrow_directed = grid::arrow(length = unit(10, "pt"), type = "closed"),
    edge_color = text_mid
  ) +
  # Nodes with colors
  geom_dag_point(
    aes(color = color_group),
    size = 20,
    show.legend = FALSE
  ) +
  # Text labels
  geom_dag_text(
    aes(label = label),
    color = "white",
    size = 3.5,
    fontface = "bold",
    family = "sans"
  ) +
  # Color scheme
  scale_color_manual(
    values = c(
      "outcome" = accent_color,
      "other" = neutral_color
    )
  ) +
  # Theme
  theme_dag() +
  labs(
    title = "Causal Diagram: Factors Influencing Wildlife-Vehicle Collisions"
  ) +
  theme(
    plot.title = element_text(
      size = 14, 
      face = "bold", 
      color = text_dark,
      hjust = 0.5
    ),
    plot.background = element_rect(fill = bg_warm, color = NA),
    panel.background = element_rect(fill = bg_warm, color = NA)
  )
```

**Key relationships:**

-   **Traffic (AADT)** directly affects roadkill probability (more vehicles → more collision opportunities)
-   **Land use** influences wildlife presence near roads (forests/parks attract wildlife) as well as road types
-   **Road type** is a common cause affecting traffic volume, and speed limits
-   **Speed limit** affects collision severity and driver reaction time
-   We control for **road type** to avoid confounding when estimating traffic effects

**NOTE**: Without considering wildlife density and surrounding habitats, this model estimates relationships conditional on unobserved wildlife presence, which is approximated using nearby land-use rather than direct population data.

------------------------------------------------------------------------

# 3. Hypothesis

Based on our causal theory, we make three sets of predictions:

| Hypothesis | Variable | Expected Effect | Rationale |
|------------------|------------------|------------------|------------------|
| **H1: Traffic** | AADT (↑) | \+ occurrence, + intensity | More vehicles → more collision opportunities |
| **H2a: Wildlife habitat** | Forest/Park (↑) | \+ occurrence, + intensity | Attracts wildlife near roads |
| **H2b: Urban development** | Residential (↑) | \- occurrence, - intensity | Reduces wildlife presence |
| **H3a: Road infrastructure** | Major roads (vs Major baseline) | \- occurrence, - intensity | Lower speeds, fewer lanes than major roads |
| **H3b: Speed** | Speed limit (↑) | \+ occurrence, + intensity | Reduced reaction time, higher mortality |

We'll test this in *both* parts of our model:

**Note:** All effects are interpreted as rates per km (controlled via offset for road length).

------------------------------------------------------------------------

# 4. Data & Methods

### Data Sources

| Dataset | Source | Variables | Coverage |
|------------------|------------------|------------------|------------------|
| Roadkill observations | Global Roadkill Database [@grilo2025] | GPS coordinates, species | 2017-2019 |
| Road network | OpenStreetMap [@osm2024] | Geometry, type, speed limits | Denmark |
| Traffic counts | Danish Road Directorate [@vejdirektoratet2019] | AADT (vehicles/day) | Monitoring stations |
| Land use | OpenStreetMap [@osm2024] | Forest, farmland, residential, parks | 500m buffers |

Technical Setup: \[`tidyverse`, `sf`, `terra`, `here`, `pscl`, `yaml`, `patchwork`, `dagitty`, `ggdag`\]

```{r}
#| label: setup
#| code-fold: true

library(tidyverse)
library(sf)
library(terra)
library(here)
library(pscl)
library(yaml)
library(patchwork)

# Load configuration
config <- read_yaml(here("posts/eds222-final/config.yml"))

set.seed(config$seed)

CRS_M <- config$crs # EPSG:25832, Denmark ETRS89 / UTM zone 32N

# Denmark bounding box (WGS84)
dk_bbox_wgs84 <- st_bbox(c(
  xmin = config$bbox_xmin,
  ymin = config$bbox_ymin,
  xmax = config$bbox_xmax,
  ymax = config$bbox_ymax
), crs = config$bbox_crs)

# Transform to projected CRS
dk_bbox_proj <- st_transform(st_as_sfc(dk_bbox_wgs84), CRS_M) %>%
  st_bbox()
```

#### Load Roadkill Observations

Roadkill observations are GPS point locations filtered to Denmark and the study period (2017-2019), then transformed to a projected coordinate system (EPSG:4326) for analysis.

```{r}
#| label: load-roadkill
#| code-fold: true

# Load roadkill CSV
road_kill_dk <- read_csv(here(config$roadkill_csv_path)) %>%
    filter(
        country == "Denmark",
        year >= 2017, year <= 2019
    ) %>%
    drop_na(decimalLongitude, decimalLatitude) %>%
    st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) %>%
    st_transform(CRS_M) %>%
    st_crop(dk_bbox_proj)
```

> -   Roadkill observations: `r format(nrow(road_kill_dk), big.mark = ",")`
> -   Time period: 2017-2019
> -   Coordinate system: ETRS89 / UTM zone 32N

#### Load Road Network

```{r}
#| label: load-roads-cached
#| code-fold: true
#| output: false

# Define cache path for roads data
roads_cache <- here(config$roads_cached_path)

if (file.exists(roads_cache)) {
  cat("Loading roads from cache...\n")
  roads_raw <- readRDS(roads_cache)
} else {
  cat("Cache not found. Loading and processing roads (one-time setup)...\n")

  # Load shapefile
  roads_raw <- st_read(here(config$roads_shp_path), quiet = TRUE) %>%
    st_transform(CRS_M) %>%
    st_crop(dk_bbox_proj)

  # Save to cache
  cat("Saving roads to cache for future runs...\n")
  saveRDS(roads_raw, roads_cache)
  cat("Cache saved:", roads_cache, "\n")
}
```

> Road segments loaded: `r format(nrow(roads_raw), big.mark = ",")`

#### Load Traffic Data

Traffic counts represent Annual Average Daily Traffic (AADT) from monitoring stations, averaged across 2017-2019.

```{r}
#| label: load-traffic-cached
#| code-fold: true
#| output: false

# Define cache path for traffic data
traffic_cache <- here(config$traffic_cached_path)

if (file.exists(traffic_cache)) {
  cat("Loading traffic data from cache...\n")
  traffic_raw <- readRDS(traffic_cache)
} else {
  cat("Cache not found. Loading and processing traffic (one-time setup)...\n")

  # Load shapefile
  traffic_raw <- st_read(here(config$traffic_shp_path), quiet = TRUE) %>%
  st_transform(CRS_M) %>%
  st_crop(dk_bbox_proj) %>%
  filter(AAR >= 2017, AAR <= 2019) %>%
  # Average AADT across years for each station
  group_by(geometry) %>%
  summarise(
    AADT = mean(AADT, na.rm = TRUE),
    AAR = "2017-2019",
    .groups = "drop"
  ) %>%
  st_as_sf()

  # Save to cache
  cat("Saving traffic to cache for future runs...\n")
  saveRDS(traffic_raw, traffic_cache)
  cat("Cache saved:", traffic_cache, "\n")
}

```

> Traffic monitoring stations: `r format(nrow(traffic_raw), big.mark = ",")`

#### Load Land Use Data

Land use polygons classify areas as forest, farmland, residential, parks, etc.

```{r}
#| label: load-landuse-cached
#| code-fold: true
#| include: false

# Define cache path for traffic data
landuse_cache <- here(config$landuse_cached_path)

if (file.exists(landuse_cache)) {
  cat("Loading land use from cache...\n")
  landuse_raw <- readRDS(landuse_cache)
} else {
  cat("Cache not found. Loading and processing land use (one-time setup)...\n")

  # Load shapefile
  landuse_raw <- st_read(here(config$landuse_shp_path), quiet = TRUE) %>%
    st_transform(CRS_M) %>%
    st_crop(dk_bbox_proj)

  # Save to cache
  cat("Saving land use to cache for future runs...\n")
  saveRDS(landuse_raw, landuse_cache)
  cat("Cache saved:", landuse_cache, "\n")
}

cat("Land use polygons loaded:", format(nrow(landuse_raw), big.mark = ","), "\n")
```

> Land use polygons: `r format(nrow(landuse_raw), big.mark = ",")`

```{r}
#| label: explore-landuse-classes
#| include: false
#| code-fold: true

# Explore land use classes
landuse_summary <- landuse_raw %>%
  st_drop_geometry() %>%
  count(fclass, sort = TRUE) %>%
  filter(!is.na(fclass))

cat("\nTop land use classes:\n")
print(head(landuse_summary, 10))
```

Top land use classes:

```{r}
#| label: show-landuse-summary
#| echo: false
knitr::kable(head(landuse_summary, 10), caption = "Top 10 Land Use Classes")
```

**Computational Note**: These shapefiles are large (millions of features); we cache the processed/projected versions to avoid reloading and processing during every run. First runs take \~5-10 minutes each; cached runs take seconds.

------------------------------------------------------------------------

### Data Processing Pipeline

#### Filter to Motorized Roads

We restrict analysis to roads accessible by motor vehicles, excluding pedestrian paths and cycleways and other places where wildlife-vehicle collisions cannot occur.

```{r}
#| label: filter-roads
#| code-fold: true
#| include: false

# Extract car codes from config
car_codes <- c(
  config$road_car_codes_major,
  config$road_car_codes_minor,
  config$road_car_codes_links
)

# Filter and calculate road lengths
car_roads <- roads_raw %>%
  filter(code %in% car_codes) %>%
  mutate(
    len_m = st_length(geometry),
    len_km = as.numeric(len_m) / 1000
  )

cat("Car-accessible roads:\n")
cat("  Segments:", format(nrow(car_roads), big.mark = ","), "\n")
cat("  Total length:", format(round(sum(car_roads$len_km), 0), big.mark = ","), "km\n")
cat("  Mean segment length:", round(mean(car_roads$len_km), 2), "km\n\n")
```

> -   Motorized road segments: `r format(nrow(car_roads), big.mark = ",")`
> -   Total road length: `r format(round(sum(car_roads$len_km)), big.mark = ",")` km
> -   Mean segment length: `r round(mean(car_roads$len_km), 2)` km

#### Match Traffic to Road Segments

Traffic monitoring stations are point locations. Since there are far more roads than monitoring stations, I assigned each road segment with the AADT from its nearest station, applying a distance threshold. This means we only assign traffic data to roads within \~3.7 km of a monitoring station, avoiding matches to stations that are unreasonably far away. This balances **coverage** (75% of roads get traffic data) with **accuracy** (avoiding spurious long-distance matches).

```{r}
#| label: match-traffic
#| code-fold: true
#| include: false

# Define cache path for distance data
distances_cache_file <- here(config$distances_cache_path)

if (file.exists(distances_cache_file)) {
  cat("Loading cached distances...\n")
  distances_data <- readRDS(distances_cache_file)
  nearest_idx <- distances_data$nearest_idx
  distances <- distances_data$distances
} else {
  cat("Computing road-to-traffic distances (one-time calculation, ~5-10 min)...\n")

  # Prepare traffic data - select only needed columns
  traffic_trim <- traffic_raw %>%
    dplyr::select(AAR, AADT, geometry)

  # Find nearest traffic point to each road
  nearest_idx <- st_nearest_feature(car_roads, traffic_trim)

  # Calculate distances
  distances <- st_distance(car_roads, traffic_trim[nearest_idx, ], by_element = TRUE)

  # Save both for next time
  saveRDS(list(nearest_idx = nearest_idx, distances = distances),
          distances_cache_file)
  cat("Distances cached:", distances_cache_file, "\n")
}

cat("Distance matching complete.\n\n")
```

```{r}
#| label: apply-threshold
#| code-fold: true

# Apply configured threshold
threshold_percentile <- config$distance_threshold_percentile
dist_threshold <- quantile(as.numeric(distances), threshold_percentile)

# Merge traffic data with roads
roads_traf <- car_roads %>%
  mutate(
    nn_dist_m = as.numeric(distances),
    AADT = if_else(nn_dist_m <= dist_threshold,
                   traffic_raw$AADT[nearest_idx],
                   NA_real_)
  )
```

> -   Distance threshold: `r format(round(dist_threshold), big.mark = ",")` m (75th percentile)
> -   Roads with traffic data: `r format(sum(!is.na(roads_traf$AADT)), big.mark = ",")` (`r round(mean(!is.na(roads_traf$AADT)) * 100, 1)`%)
> -   AADT range: `r format(min(roads_traf$AADT, na.rm = TRUE), big.mark = ",")` - `r format(max(roads_traf$AADT, na.rm = TRUE), big.mark = ",")` vehicles/day

**Note**: Analysis is limited to Denmark's *monitored* road network (major highways and urban roads). Remote rural roads are likely not included.

------------------------------------------------------------------------

#### Extract Land Use Around Roads

We calculate the percentage of forest, farmland, residential, and park land use within 500m buffers around each road segment. This distance approximates wildlife movement ranges and habitat edge effects.

```{r}
#| label: extract-landuse
#| code-fold: true
#| include: false

# Define cache path for landuse data
landuse_cache_file <- here(config$landuse_props_path)

if (file.exists(landuse_cache_file)) {
  cat("Loading cached land use proportions...\n")
  lu_props <- readRDS(landuse_cache_file)
} else {
  cat("Extracting land use via RASTER...\n\n")
  
  library(terra)
  
  # Rasterize land use
  cat("Converting land use to raster (~2-3 min)...\n")
  
  # Get extent from roads
  roads_extent <- st_bbox(roads_traf) %>% st_as_sfc() %>% st_buffer(1000)
  
  # Create raster template (100m resolution)
  rast_template <- rast(
    ext(vect(roads_extent)),
    resolution = 100,
    crs = crs(vect(roads_traf))
  )
  
  cat("  Rasterizing", nrow(landuse_raw), "polygons...\n")
  
  # Convert fclass to numeric codes for rasterization
  landuse_coded <- landuse_raw %>%
    mutate(fclass_num = as.numeric(as.factor(fclass)))
  
  fclass_lookup <- landuse_coded %>%
    st_drop_geometry() %>%
    distinct(fclass, fclass_num)
  
  # Rasterize
  landuse_raster <- rasterize(
    vect(landuse_coded),
    rast_template,
    field = "fclass_num"
  )
  
  cat("  Raster created.\n\n")
  
  # Extract for road buffers
  cat("Extracting land use for road buffers...\n")
  
  roads_with_id <- roads_traf %>%
    mutate(road_id = row_number())
  
  road_buffers <- roads_with_id %>%
    st_buffer(config$road_buffer_distance) %>%
    dplyr::select(road_id)
  
  cat("  Extracting raster values (this takes 2-5 min)...\n")
  
  # Extract all raster cells within each buffer
  extracted <- extract(landuse_raster, vect(road_buffers), fun = NULL)
  
  cat("  Extraction complete. Calculating proportions...\n")
  
  # Calculate proportions
  landuse_props <- extracted %>%
    as_tibble() %>%
    rename(road_id = ID, fclass_num = 2) %>%
    filter(!is.na(fclass_num)) %>%
    left_join(fclass_lookup, by = "fclass_num") %>%
    count(road_id, fclass) %>%
    group_by(road_id) %>%
    mutate(pct = n / sum(n) * 100) %>%
    ungroup() %>%
    dplyr::select(road_id, fclass, pct) %>%
    pivot_wider(
      names_from = fclass,
      values_from = pct,
      values_fill = 0,
      names_prefix = "pct_"
    )
  
  # Add missing columns with 0 before combining
  lu_props <- landuse_props
  
  if (!"pct_forest" %in% names(lu_props)) lu_props$pct_forest <- 0
  if (!"pct_scrub" %in% names(lu_props)) lu_props$pct_scrub <- 0
  if (!"pct_farmland" %in% names(lu_props)) lu_props$pct_farmland <- 0
  if (!"pct_farmyard" %in% names(lu_props)) lu_props$pct_farmyard <- 0
  if (!"pct_meadow" %in% names(lu_props)) lu_props$pct_meadow <- 0
  if (!"pct_orchard" %in% names(lu_props)) lu_props$pct_orchard <- 0
  if (!"pct_vineyard" %in% names(lu_props)) lu_props$pct_vineyard <- 0
  if (!"pct_residential" %in% names(lu_props)) lu_props$pct_residential <- 0
  if (!"pct_park" %in% names(lu_props)) lu_props$pct_park <- 0
  if (!"pct_nature_reserve" %in% names(lu_props)) lu_props$pct_nature_reserve <- 0
  if (!"pct_recreation_ground" %in% names(lu_props)) lu_props$pct_recreation_ground <- 0
  if (!"pct_grass" %in% names(lu_props)) lu_props$pct_grass <- 0
  
  # Combine related land use types
  lu_props <- lu_props %>%
    mutate(
      pct_forest = pct_forest + pct_scrub,
      pct_farmland = pct_farmland + pct_farmyard + pct_meadow + pct_orchard + pct_vineyard,
      pct_residential = pct_residential,
      pct_park = pct_park + pct_nature_reserve + pct_recreation_ground + pct_grass
    ) %>%
    dplyr::select(road_id, pct_forest, pct_farmland, pct_residential, pct_park)
  
  # Fill missing roads with 0
  complete_roads <- tibble(road_id = 1:nrow(roads_traf))
  
  lu_props <- complete_roads %>%
    left_join(lu_props, by = "road_id") %>%
    mutate(across(starts_with("pct_"), ~ replace_na(., 0)))
  
  saveRDS(lu_props, landuse_cache_file)
  cat("\nCache saved\n")
}


cat("Roads with land use data:", format(nrow(lu_props), big.mark = ","), "\n")
cat("Mean % Forest:", round(mean(lu_props$pct_forest), 1), "%\n")
cat("Mean % Farmland:", round(mean(lu_props$pct_farmland), 1), "%\n")
cat("Mean % Residential:", round(mean(lu_props$pct_residential), 1), "%\n")
cat("Mean % Park:", round(mean(lu_props$pct_park), 1), "%\n")
```

Mean land use composition within 500m:

> -   Forest: `r round(mean(lu_props$pct_forest), 1)`%
> -   Farmland: `r round(mean(lu_props$pct_farmland), 1)`%
> -   Residential: `r round(mean(lu_props$pct_residential), 1)`%
> -   Parks: `r round(mean(lu_props$pct_park), 1)`%

#### Aggregate Roadkill by Road Segment

Each roadkill point is matched to its nearest road segment using spatial join.

```{r}
#| label: aggregate-roadkill
#| code-fold: true
#| include: false

# Define cache path for aggregated roadkill data
roadkill_cache_file <- here(config$roadkill_cache_path)

if (file.exists(roadkill_cache_file)) {
  cat("Loading cached roadkill aggregation...\n")
  roadkill_by_segment <- readRDS(roadkill_cache_file)
} else {
  cat("Computing roadkill aggregation (spatial join, ~2-5 min)...\n")

  # Spatial join: roadkill points to nearest road
  roadkill_by_segment <- road_kill_dk %>%
    st_join(roads_traf %>% dplyr::select(osm_id),
            join = st_nearest_feature) %>%
    group_by(osm_id) %>%
    summarise(roadkill_count = n(), .groups = "drop") %>%
    st_drop_geometry()

  saveRDS(roadkill_by_segment, roadkill_cache_file)
  cat("Cache saved:", roadkill_cache_file, "\n")
}

cat("Roadkill aggregation complete.\n")
cat("  Unique road segments with roadkill:",
    format(nrow(roadkill_by_segment), big.mark = ","), "\n\n")
```

> -   Road segments with roadkill: `r format(nrow(roadkill_by_segment), big.mark = ",")`

#### Create Final Analysis Dataset

We merge all data sources and apply transformations required for modeling: log-transform traffic and road length, classify road types, and assign missing speed limits.

```{r}
#| label: create-model-data
#| code-fold: true
#| include: false

# Merge all data sources
model_data <- roads_traf %>%
  st_drop_geometry() %>%
  mutate(road_id = row_number()) %>%
  left_join(roadkill_by_segment, by = "osm_id") %>%
  left_join(lu_props, by = "road_id") %>%
  replace_na(list(roadkill_count = 0)) %>%
  # Fill missing land use with 0
  mutate(across(starts_with("pct_"), ~ replace_na(., 0))) %>%
  filter(!is.na(AADT), AADT > 0) %>%
  mutate(
    # Log transforms for modeling
    log_AADT = log(AADT),
    log_len_km = log(len_km),

    # Road type classification
    road_type = case_when(
      code %in% config$road_car_codes_major ~ "Major",
      code %in% config$road_car_codes_minor ~ "Minor",
      TRUE ~ "Other"
    ),

    # Speed limit (convert to numeric, impute missing with median)
    speed_limit = as.numeric(maxspeed),
    speed_limit = if_else(is.na(speed_limit),
                          median(speed_limit, na.rm = TRUE),
                          speed_limit)
  )

cat("Total segments:", format(nrow(model_data), big.mark = ","), "\n")
cat("Segments with roadkill:",
    format(sum(model_data$roadkill_count > 0), big.mark = ","),
    "(", round(mean(model_data$roadkill_count > 0) * 100, 1), "%)\n")
cat("Zero-inflation rate:",
    round(mean(model_data$roadkill_count == 0) * 100, 1), "%\n")
cat("Mean roadkill per segment:", round(mean(model_data$roadkill_count), 3), "\n")
cat("Variance:", round(var(model_data$roadkill_count), 3), "\n")
cat("Variance/Mean ratio (dispersion):",
    round(var(model_data$roadkill_count) / mean(model_data$roadkill_count), 2), "\n")
cat("Total roadkill events:", format(sum(model_data$roadkill_count), big.mark = ","), "\n\n")
```

```{r}
#| label: dataset-summary
#| echo: false

summary_stats <- tibble(
  Metric = c(
    "Road segments",
    "Segments with roadkill",
    "Zero-inflation rate",
    "Total roadkill events",
    "Mean roadkill per segment",
    "Overdispersion (Var/Mean)"
  ),
  Value = c(
    format(nrow(model_data), big.mark = ","),
    paste0(format(sum(model_data$roadkill_count > 0), big.mark = ","), 
           " (", round(mean(model_data$roadkill_count > 0) * 100, 1), "%)"),
    paste0(round(mean(model_data$roadkill_count == 0) * 100, 1), "%"),
    format(sum(model_data$roadkill_count), big.mark = ","),
    round(mean(model_data$roadkill_count), 3),
    round(var(model_data$roadkill_count) / mean(model_data$roadkill_count), 2)
  )
)

knitr::kable(summary_stats, caption = "Final Dataset Characteristics")
```

**Key observations**:

> -   High zero-inflation (`r round(mean(model_data$roadkill_count == 0) * 100, 1)`%) justifies hurdle model
> -   Overdispersion (Var/Mean = `r round(var(model_data$roadkill_count) / mean(model_data$roadkill_count), 2)`) justifies negative binomial distribution

------------------------------------------------------------------------

# 5. Exploratory Analysis

::: panel-tabset

```{r}
#| label: predictor-distributions
#| echo: false
#| fig-width: 14
#| fig-height: 12

library(patchwork)

# 1. Distribution of continuous predictors
p_aadt_dist <- ggplot(model_data, aes(x = AADT)) +
  geom_histogram(fill = primary_color, color = "white", alpha = 0.8, bins = 50) +
  scale_x_log10(labels = scales::comma) +
  labs(
    title = "Distribution of Traffic Volume",
    x = "AADT (vehicles/day, log scale)",
    y = "Count of Road Segments"
  ) +
  theme_cohesive()

p_length_dist <- ggplot(model_data, aes(x = len_km)) +
  geom_histogram(fill = primary_color, color = "white", alpha = 0.8, bins = 50) +
  scale_x_log10() +
  labs(
    title = "Distribution of Road Segment Length",
    x = "Length (km, log scale)",
    y = "Count of Road Segments"
  ) +
  theme_cohesive()

p_speed_dist <- ggplot(model_data, aes(x = speed_limit)) +
  geom_histogram(fill = primary_color, color = "white", alpha = 0.8, binwidth = 10) +
  labs(
    title = "Distribution of Speed Limits",
    x = "Speed Limit (km/h)",
    y = "Count of Road Segments"
  ) +
  theme_cohesive()

# 2. Land use distributions
landuse_long <- model_data %>%
  select(pct_forest, pct_farmland, pct_residential, pct_park) %>%
  pivot_longer(everything(), names_to = "landuse_type", values_to = "percentage") %>%
  mutate(landuse_type = str_replace(landuse_type, "pct_", "") %>% str_to_title())

p_landuse_dist <- ggplot(landuse_long, aes(x = percentage, fill = landuse_type)) +
  geom_histogram(alpha = 0.8, bins = 30) +
  facet_wrap(~landuse_type, scales = "free_y") +
  scale_fill_manual(values = c(
    "Forest" = backup_color,
    "Farmland" = accent_color,
    "Residential" = primary_color,
    "Park" = neutral_color
  )) +
  labs(
    title = "Distribution of Land Use Types (within 500m buffers)",
    x = "Percentage of Buffer Area",
    y = "Count of Road Segments"
  ) +
  theme_cohesive() +
  theme(legend.position = "none")

# 3. Categorical predictor - Road type
p_roadtype <- model_data %>%
  count(road_type) %>%
  ggplot(aes(x = reorder(road_type, n), y = n, fill = road_type)) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  scale_fill_manual(values = c(
    "Major" = accent_color,
    "Minor" = primary_color,
    "Other" = neutral_color
  )) +
  coord_flip() +
  labs(
    title = "Distribution of Road Types",
    x = "Road Type",
    y = "Count of Road Segments"
  ) +
  theme_cohesive()

# Combine distribution plots
(p_aadt_dist + p_length_dist) / (p_speed_dist + p_roadtype) / p_landuse_dist
```

## Visualizations

![](eda_visualization_themed2.png)

## Key patterns

**Predictor Distributions:**

1. **Traffic volume** (top left): Log-normally distributed, centered around 1,000-10,000 vehicles/day, justifying log-transformation in the model
2. **Road segment length** (top right): Also log-normally distributed (0.01-1 km typical), supporting the use of a length offset
3. **Speed limits** (middle left): Speed limits show two distinct clusters - most roads either low-speed (~50 km/h) or have missing values
4. **Road types** (middle right): Network dominated by Minor roads (~150,000 segments), with Major roads (~50,000) and Other types (~5,000) less common
5. **Land use composition** (bottom): Within 500m buffers, farmland shows right-skewed distribution (0-20% typical), forest is more evenly distributed across 0-60%, parks are highly concentrated at 0% (rare feature), and residential areas are either sparse or dense with little in between

:::

These patterns validate our hypotheses from the DAG. Now let's build a statistical model to quantify these effects.

------------------------------------------------------------------------

# 6. Statistical Model: The Hurdle Approach

### Why a Hurdle Model?

Traditional count models (Poisson, negative binomial) underestimate zeros. Our data exhibits:

-   Excess zeros: `r round(mean(model_data$roadkill_count == 0) * 100, 1)`% of segments have no roadkill

-   Overdispersion: Variance (`r round(var(model_data$roadkill_count), 2)`) \>\> Mean (`r round(mean(model_data$roadkill_count), 3)`)

A **hurdle model** separates two processes:

1.  **Binary hurdle** (logistic): Does roadkill occur at all?
2.  **Count component** (negative binomial): How many events, given occurrence?

### Model Specification

A **hurdle model** separates the data-generating process into two parts:

**Part 1: Zero hurdle (Binary component)**

Models whether any roadkill occurs on a road segment.

$$
\begin{aligned}
Z_i &\sim \text{Binomial}(p_i) \\
\text{logit}(p_i) &= \alpha_0 + \alpha_1 \log(\text{AADT}_i) + \alpha_2 \text{Minor}_i\\
&\quad + \alpha_4 \text{Speed}_i + \alpha_5 \text{Forest}_i + \alpha_6 \text{Farm}_i \\
&\quad + \alpha_7 \text{Residential}_i + \alpha_8 \text{Park}_i
\end{aligned}
$$

where:

-   $Z_i = 1$ if roadkill occurs, $Z_i = 0$ otherwise

-   $\p_i$ is the probability of observing any roadkill on segment $i$

-   $\text{Minor}_i$ is an indicator for road type (0 or 1; reference level: Major roads (0))

**Part 2: Count component (Positive counts only)**

Models the number of roadkill events, conditional on at least one event occurring ($Z_i = 1$).

$$
\begin{aligned}
Y_i | Z_i = 1 &\sim \text{Negative Binomial}(\mu_i, \theta) \\
\log(\mu_i) &= \beta_0 + \beta_1 \log(\text{AADT}_i) + \beta_2 \text{Minor}_i \\
&\quad + \beta_4 \text{Speed}_i + \beta_5 \text{Forest}_i + \beta_6 \text{Farm}_i \\
&\quad + \beta_7 \text{Residential}_i + \beta_8 \text{Park}_i + \log(\text{Length}_i)
\end{aligned}
$$

where:

-   $Y_i$ is the count of roadkill events on segment $i$

-   $\mu_i$ is the expected count given occurrence - $\theta$ is the dispersion parameter

-   $\log(\text{Length}_i)$ is an offset controlling for road segment exposure

**Why Negative Binomial?**

Our data show overdispersion (Variance/Mean = `r round(var(model_data$roadkill_count) / mean(model_data$roadkill_count), 2)`), which violates the Poisson assumption that variance equals the mean. The Negative Binomial distribution allows $\text{Var}(Y_i) > \mathbb{E}[Y_i]$.

#### Model Validation: Simulation Test

Before applying to real data, we verify the model recovers known parameters from simulated data.

```{r}
#| label: simulate-hurdle1
#| code-fold: true

set.seed(42)
n_sim <- 10000
x_sim <- rnorm(n_sim, mean = 10, sd = 2)

# True parameters for hurdle model
beta0_zero <- -0.5   # Zero component models P(Y > 0)
beta1_zero <- 0.3    
beta0_count <- 0.5   # Count component models E[Y | Y > 0]
beta1_count <- 0.2   
theta <- 1.5         # Dispersion parameter

# Generate binary outcomes (does roadkill occur?)
logit_prob_nonzero <- beta0_zero + beta1_zero * x_sim
prob_nonzero <- plogis(logit_prob_nonzero)
z_sim <- rbinom(n_sim, size = 1, prob = prob_nonzero)

# Generate positive counts for non-zero cases
mu_untruncated <- exp(beta0_count + beta1_count * x_sim)
y_counts <- numeric(n_sim)

# Generate all counts 
temp_counts <- rnbinom(n_sim, mu = mu_untruncated, size = theta)
# Truncate at 1 (reject zeros, replace with next draw)
while(any(temp_counts == 0 & z_sim == 1)) {
  need_redraw <- (temp_counts == 0 & z_sim == 1)
  temp_counts[need_redraw] <- rnbinom(sum(need_redraw), 
                                      mu = mu_untruncated[need_redraw], 
                                      size = theta)
}
y_sim <- temp_counts * z_sim  # Multiply by occurrence (zeros out non-occurrences)

sim_data <- tibble(x = x_sim, y = y_sim)
```

Simulated data characteristics:

> -   Zero rate: `r round(mean(sim_data$y == 0) * 100, 1)`%
> -   Mean count (all): `r round(mean(sim_data$y), 3)`
> -   Mean count (non-zero only): `r round(mean(sim_data$y[sim_data$y > 0]), 3)`

```{r}
#| label: fit-simulated
#| code-fold: true

# Fit hurdle model to simulated data
sim_hurdle <- hurdle(y ~ x, data = sim_data, dist = "negbin")

# Extract estimated parameters
sim_coefs <- coef(sim_hurdle)
```

#### Parameter recovery check

```{r}
#| label: recovery-check
#| code-fold: true

# Check parameter
zero_intercept <- sim_coefs["zero_(Intercept)"]
zero_slope <- sim_coefs["zero_x"]
count_intercept <- sim_coefs["count_(Intercept)"]
count_slope <- sim_coefs["count_x"]

recovery_table <- tibble(
  Component = c("Zero", "Zero", "Count", "Count"),
  Parameter = c("Intercept", "Slope", "Intercept", "Slope"),
  `True Value` = c(beta0_zero, beta1_zero, beta0_count, beta1_count),
  Estimated = round(c(zero_intercept, zero_slope, count_intercept, count_slope), 3),
  Difference = round(c(zero_intercept, zero_slope, count_intercept, count_slope) - 
                     c(beta0_zero, beta1_zero, beta0_count, beta1_count), 3)
) %>%
  mutate(Recovered = ifelse(abs(Difference) < 0.2, "✓", "✗"))

knitr::kable(recovery_table, caption = "Parameter Recovery Check: Simulated Data", digits = 3)
```

Conclusion: Model successfully recovers known parameters (differences \< 0.2). We can apply it to real data with confidence.

Next, we use our model predictions to calculate the standard error.

```{r}
#| label: simulation-predictions
#| echo: false
#| code-fold: true

# Create prediction grid
x_grid <- seq(min(sim_data$x), max(sim_data$x), length.out = 100)
pred_data <- tibble(x = x_grid)

# Extract coefficients and variance-covariance matrix
coef_zero <- coef(sim_hurdle, model = "zero")
coef_count <- coef(sim_hurdle, model = "count")
vcov_zero <- vcov(sim_hurdle)[1:2, 1:2]  # First 2 rows/cols are zero component
vcov_count <- vcov(sim_hurdle)[3:4, 3:4]  # Next 2 are count component

# Zero component: Calculate predictions and SEs on logit scale
# Linear predictor: intercept + slope * x
logit_pred <- coef_zero[1] + coef_zero[2] * pred_data$x

# Standard error calculation
# For each x value: SE = sqrt(var(intercept) + x^2*var(slope) + 2*x*cov(intercept,slope))
se_logit <- sqrt(
  vcov_zero[1,1] +                          # variance of intercept
  pred_data$x^2 * vcov_zero[2,2] +          # variance of slope * x^2
  2 * pred_data$x * vcov_zero[1,2]          # covariance term
)

# Transform to probability scale with CI
pred_data <- pred_data %>%
  mutate(
    prob_nonzero = plogis(logit_pred),
    prob_lower = plogis(logit_pred - 1.96 * se_logit),
    prob_upper = plogis(logit_pred + 1.96 * se_logit)
  )

# Count Component: Calculate predictions and SEs on log scale
log_pred <- coef_count[1] + coef_count[2] * pred_data$x


# Standard error calculation
se_log <- sqrt(
  vcov_count[1,1] +                         # variance of intercept
  pred_data$x^2 * vcov_count[2,2] +         # variance of slope * x^2
  2 * pred_data$x * vcov_count[1,2]         # covariance term
)

# Transform to count scale with CI
pred_data <- pred_data %>%
  mutate(
    count_given_nonzero = exp(log_pred),
    count_lower = exp(log_pred - 1.96 * se_log),
    count_upper = exp(log_pred + 1.96 * se_log)
  )
```

```{r}
#| label: sim-visualization
#| echo: false
#| code-fold: true
#| fig-height: 4
#| fig-width: 10

# Plot 1: Zero hurdle component
p_sim1 <- ggplot() +
  # Raw binned proportions
  stat_summary_bin(
    data = sim_data,
    aes(x = x, y = as.numeric(y > 0)),
    fun = mean,
    geom = "point",
    bins = 20,
    color = primary_color,
    size = 3,
    alpha = 0.6
  ) +
  # Confidence ribbon
  geom_ribbon(
    data = pred_data,
    aes(x = x, ymin = prob_lower, ymax = prob_upper),
    alpha = 0.2,
    fill = accent_color
  ) +
  # Prediction line
  geom_line(
    data = pred_data, 
    aes(x = x, y = prob_nonzero), 
    color = accent_color, 
    linewidth = 1.2
  ) +
  labs(
    title = "A. Hurdle Component: Probability of Non-Zero",
    x = "Predictor (x)", 
    y = "Probability of Roadkill Occurrence"
  ) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  theme_cohesive()

# Plot 2: Count component
p_sim2 <- ggplot() +
  # Raw data points
  geom_point(
    data = sim_data %>% filter(y > 0),
    aes(x = x, y = y), 
    color = primary_color, 
    alpha = 0.4,
    size = 2
  ) +
  # Confidence ribbon
  geom_ribbon(
    data = pred_data,
    aes(x = x, ymin = count_lower, ymax = count_upper),
    alpha = 0.2,
    fill = accent_color
  ) +
  # Prediction line
  geom_line(
    data = pred_data, 
    aes(x = x, y = count_given_nonzero),
    color = accent_color, 
    linewidth = 1.2
  ) +
  labs(
    title = "B. Count Component: Intensity Given Presence",
    x = "Predictor (x)", 
    y = "Count (y | y > 0)"
  ) +
  theme_cohesive()

# Combine and add shared subtitle
p_sim1 + p_sim2 +
  plot_annotation(
    subtitle = "Points = raw data, Lines = model predictions, Ribbons = 95% CI",
    theme = theme(
      plot.subtitle = element_text(size = 11, color = text_mid, hjust = 0.5)
    )
  )
```

**Key Takeaway**: When we feed the hurdle model data generated from known parameters, it successfully recovers those parameters. This gives us confidence to apply it to real data where the true parameters are unknown.

------------------------------------------------------------------------

# 7. Results

### Fit Model to Real Data

```{r}
#| label: fit-model
#| code-fold: true

# Full model with traffic, road characteristics, and land use
hurdle_model <- hurdle(
  roadkill_count ~ log_AADT + road_type + speed_limit +
                   pct_forest + pct_farmland + pct_residential + pct_park |
                   log_AADT + road_type + speed_limit +
                   pct_forest + pct_farmland + pct_residential + pct_park,
  data = model_data,
  offset = log(len_km),  # Controls for road length exposure
  dist = config$model_distribution,
  zero.dist = config$model_zero_dist
)
```

#### Model Diagnostics

> -   Log-Likelihood: `r round(logLik(hurdle_model), 1)`
> -   AIC: `r round(AIC(hurdle_model), 1)`
> -   BIC: `r round(BIC(hurdle_model), 1)`

### Model Coefficients

```{r}
#| label: results-table
#| code-fold: true
#| echo: false

# Extract coefficients
coefs <- coef(hurdle_model)
se <- sqrt(diag(vcov(hurdle_model)))

results <- tibble(
  Parameter = names(coefs),
  Estimate = round(coefs, 4),
  SE = round(se, 4),
  Z_value = round(coefs/se, 2),
  P_value = round(2 * (1 - pnorm(abs(coefs/se))), 5)
) %>%
  mutate(Sig = case_when(
    P_value < 0.001 ~ "***",
    P_value < 0.01 ~ "**",
    P_value < 0.05 ~ "*",
    P_value < 0.1 ~ ".",
    TRUE ~ ""
  ))

knitr::kable(results, caption = "Hurdle Model Results")
```

#### Interpretation guide:

-   **Zero component**: Coefficients are log-odds. Positive → increases probability of roadkill occurring

-   **Count component**: Coefficients are on log scale. Positive → increases expected count given occurrence

-   **Significance**: \*\*\* p\<0.001, \*\* p\<0.01, \* p\<0.05

### Model Fit to Data

This visualization shows how well our hurdle model captures the observed roadkill patterns.

```{r}
#| label: calculate-predictions
#| fig-width: 14
#| fig-height: 10
#| echo: false

# Extract model coefficients
coef_zero <- coef(hurdle_model, model = "zero")
coef_count <- coef(hurdle_model, model = "count")
n_zero <- length(coef_zero)
vcov_full <- vcov(hurdle_model)
vcov_zero <- vcov_full[1:n_zero, 1:n_zero]
vcov_count <- vcov_full[(n_zero+1):(n_zero+length(coef_count)), 
                        (n_zero+1):(n_zero+length(coef_count))]

# Create prediction data
forest_seq <- seq(0, max(model_data$pct_forest), length.out = 100)

newdata_forest <- tibble(
  pct_forest = forest_seq,
  log_AADT = median(model_data$log_AADT),
  road_type = factor("Major", levels = levels(factor(model_data$road_type))),
  speed_limit = median(model_data$speed_limit),
  pct_farmland = median(model_data$pct_farmland),
  pct_residential = median(model_data$pct_residential),
  pct_park = median(model_data$pct_park)
)

# Create design matrix using newdata_forest
X_forest <- model.matrix(~ log_AADT + road_type + speed_limit +         pct_forest + pct_farmland + pct_residential + pct_park,
                        data = newdata_forest)

# Zero component predictions with CI
logit_pred <- X_forest %*% coef_zero
se_logit <- sqrt(diag(X_forest %*% vcov_zero %*% t(X_forest)))

newdata_forest <- newdata_forest %>%
  mutate(
    prob_nonzero = plogis(logit_pred),
    prob_lower = plogis(logit_pred - 1.96 * se_logit),
    prob_upper = plogis(logit_pred + 1.96 * se_logit)
  )

# Count component predictions with CI
log_pred <- X_forest %*% coef_count
se_log <- sqrt(diag(X_forest %*% vcov_count %*% t(X_forest)))

newdata_forest <- newdata_forest %>%
  mutate(
    count_given_nonzero = exp(log_pred),
    count_lower = exp(log_pred - 1.96 * se_log),
    count_upper = exp(log_pred + 1.96 * se_log)
  )

# Road type effect predictions
newdata_roadtype <- tibble(
  road_type = factor(c("Major", "Minor", "Other"), 
                     levels = levels(factor(model_data$road_type))),
  log_AADT = median(model_data$log_AADT),
  speed_limit = median(model_data$speed_limit),
  pct_forest = median(model_data$pct_forest),
  pct_farmland = median(model_data$pct_farmland),
  pct_residential = median(model_data$pct_residential),
  pct_park = median(model_data$pct_park),
  len_km = 1,
  log_len_km = 0
)

X_roadtype <- model.matrix(~ log_AADT + road_type + speed_limit + 
                            pct_forest + pct_farmland + pct_residential + pct_park,
                          data = newdata_roadtype)

# Zero component with CI
logit_pred_rt <- X_roadtype %*% coef_zero
se_logit_rt <- sqrt(diag(X_roadtype %*% vcov_zero %*% t(X_roadtype)))

newdata_roadtype <- newdata_roadtype %>%
  mutate(
    prob_nonzero = plogis(logit_pred_rt),
    prob_lower = plogis(logit_pred_rt - 1.96 * se_logit_rt),
    prob_upper = plogis(logit_pred_rt + 1.96 * se_logit_rt)
  )

# Count component with CI
log_pred_rt <- X_roadtype %*% coef_count
se_log_rt <- sqrt(diag(X_roadtype %*% vcov_count %*% t(X_roadtype)))

newdata_roadtype <- newdata_roadtype %>%
  mutate(
    count_given_nonzero = exp(log_pred_rt),
    count_lower = exp(log_pred_rt - 1.96 * se_log_rt),
    count_upper = exp(log_pred_rt + 1.96 * se_log_rt)
  )

# Prepare empirical data for comparison
empirical_roadtype_occurrence <- model_data %>%
  group_by(road_type) %>%
  summarise(
    empirical_prob = mean(roadkill_count > 0),
    .groups = "drop"
  )

empirical_roadtype_intensity <- model_data %>%
  filter(roadkill_count > 0) %>%
  mutate(rate_per_km = roadkill_count / len_km)
```

```{r}
#| label: plot-occurrence-row
#| code-fold: true
#| fig-width: 14
#| fig-height: 5

# Plot 1: Forest effect on occurrence
p1 <- ggplot() +
  stat_summary_bin(
    data = model_data,
    aes(x = pct_forest, y = as.numeric(roadkill_count > 0)),
    fun = mean,
    geom = "point",
    bins = 20,
    color = primary_color,
    size = 2,
    alpha = 0.6
  ) +
  geom_ribbon(
    data = newdata_forest,
    aes(x = pct_forest, ymin = prob_lower, ymax = prob_upper),
    alpha = 0.2,
    fill = accent_color
  ) +
  geom_line(
    data = newdata_forest,
    aes(x = pct_forest, y = prob_nonzero),
    color = accent_color,
    linewidth = 1.2
  ) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "A. Does Roadkill Occur? (Zero Hurdle)",
    subtitle = "Forest coverage strongly predicts IF roadkill happens",
    x = "% Forest within 500m",
    y = "Probability of Any Roadkill"
  ) +
  theme_cohesive()

# Plot 2: Road type occurrence (consistent style with Plot 4)
p2 <- ggplot() +
  # Background: observed proportions as semi-transparent points
  geom_point(
    data = empirical_roadtype_occurrence,
    aes(x = road_type, y = empirical_prob),
    color = primary_color,
    alpha = 0.4,
    size = 8
  ) +
  # Model predictions with error bars
  geom_errorbar(
    data = newdata_roadtype,
    aes(x = road_type, ymin = prob_lower, ymax = prob_upper),
    width = 0.2,
    color = accent_color,
    linewidth = 1.2
  ) +
  geom_point(
    data = newdata_roadtype,
    aes(x = road_type, y = prob_nonzero),
    color = accent_color,
    size = 4
  ) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "B. Does Roadkill Occur? (Zero Hurdle)",
    subtitle = "Major roads 7x more likely to have roadkill",
    x = "Road Type",
    y = "Probability of Any Roadkill"
  ) +
  theme_cohesive()

p1 + p2
```

```{r}
#| label: plot-intensity-row
#| code-fold: true
#| fig-width: 14
#| fig-height: 5

# Plot 3: Forest effect on intensity
p3 <- ggplot() +
  geom_point(
    data = model_data %>% filter(roadkill_count > 0),
    aes(x = pct_forest, y = roadkill_count / len_km),
    color = primary_color,
    alpha = 0.3,
    size = 1.5
  ) +
  geom_ribbon(
    data = newdata_forest,
    aes(x = pct_forest, ymin = count_lower, ymax = count_upper),
    alpha = 0.2,
    fill = accent_color
  ) +
  geom_line(
    data = newdata_forest,
    aes(x = pct_forest, y = count_given_nonzero),
    color = accent_color,
    linewidth = 1.2
  ) +
  scale_y_log10() +
  labs(
    title = "C. How Much Roadkill? (Count Component)",
    subtitle = "Forest has weak effect on intensity (nearly flat line)",
    x = "% Forest within 500m",
    y = "Roadkill Events per km"
  ) +
  theme_cohesive()

# Plot 4: Road type intensity (consistent style with Plot 2)
p4 <- ggplot() +
  # Background: jittered observed data points
  geom_jitter(
    data = empirical_roadtype_intensity,
    aes(x = road_type, y = rate_per_km),
    color = primary_color,
    alpha = 0.2,
    width = 0.15,
    height = 0,
    size = 1.5
  ) +
  # Model predictions with error bars
  geom_errorbar(
    data = newdata_roadtype,
    aes(x = road_type, ymin = count_lower, ymax = count_upper),
    width = 0.2,
    color = accent_color,
    linewidth = 1.2
  ) +
  geom_point(
    data = newdata_roadtype,
    aes(x = road_type, y = count_given_nonzero),
    color = accent_color,
    size = 4
  ) +
  scale_y_log10() +
  labs(
    title = "D. How Much Roadkill? (Count Component)",
    subtitle = "Road type also affects intensity, but less dramatically",
    x = "Road Type",
    y = "Roadkill Events per km"
  ) +
  theme_cohesive()

p3 + p4
```

**Figure: Hurdle Model Fit**. Green = observed data, Orange = model predictions with 95% CI. Top row shows OCCURRENCE (zero hurdle): whether roadkill happens at all. Bottom row shows INTENSITY (count component): how many events occur, conditional on occurrence. Panels B and D now use consistent point + error bar styling for easy comparison between occurrence and intensity effects.

### Model Fit: Separating Occurrence from Intensity

The model successfully captures two distinct processes revealed in the data:

**Left column (Forest effect):** Panel A shows forest coverage strongly predicts whether roadkill occurs - probability rises from \~2% to \~20% as forest increases from 0% to 100%. However, Panel C shows that once roadkill does occur, forest has minimal effect on intensity (nearly flat trend line). Forest acts as a "gatekeeper" for occurrence but not intensity.

**Right column (Road type effect):** Panel B shows Major roads are 7x more likely to experience any roadkill than Minor roads (\~7% vs \~1% probability). Panel D shows Major roads also have slightly higher intensity when roadkill does occur, though the difference is less dramatic than for occurrence.

**Model performance:** The tight agreement between observed data (green) and predictions (orange with 95% CI) confirms the hurdle model adequately captures these relationships. The distinct patterns between top and bottom rows validate our two-component modeling approach - a single count model would miss this

### Hypothesis Testing

```{r}
#| label: verify-results
#| echo: false
#| include: false

# Verify key results exist
if(!"zero_log_AADT" %in% results$Parameter) {
  stop("Missing zero_log_AADT in results")
}
```

```{r}
#| label: extract-key-results
#| echo: false

# Extract key coefficients for hypothesis tests
get_coef <- function(param_name) {
  results %>% filter(grepl(param_name, Parameter))
}

traffic_zero <- get_coef("zero_log_AADT")
traffic_count <- get_coef("count_log_AADT")
forest_zero <- get_coef("zero_pct_forest")
forest_count <- get_coef("count_pct_forest")
residential_zero <- get_coef("zero_pct_residential")
residential_count <- get_coef("count_pct_residential")
# Since Major is the baseline, Minor shows the effect relative to Major
minor_zero <- get_coef("zero_road_typeMinor")
minor_count <- get_coef("count_road_typeMinor")
speed_zero <- get_coef("zero_speed_limit")
speed_count <- get_coef("count_speed_limit")
```

#### H1: Traffic Volume Effect

::::: columns
::: column
**Occurrence component:**

-   Coefficient: `r traffic_zero$Estimate`, SE: `r traffic_zero$SE`, p = `r traffic_zero$P_value` `r traffic_zero$Sig`

-   Result: Traffic `r ifelse(traffic_zero$P_value < 0.05, "significantly", "does not significantly")` affect `r ifelse(traffic_zero$P_value < 0.05, "s", "")` roadkill probability
:::

::: column
**Intensity component:**

-   Coefficient: `r traffic_count$Estimate`, SE: `r traffic_count$SE`, p = `r traffic_count$P_value` `r traffic_count$Sig`

-   Result: Traffic `r ifelse(traffic_count$P_value < 0.05, "significantly", "does not significantly")` affect `r ifelse(traffic_count$P_value < 0.05, "s", "")` collision intensity
:::
:::::

::::: columns
::: column
H1 Status: `r ifelse(traffic_zero$P_value < 0.05 | traffic_count$P_value < 0.05, "**SUPPORTED**", "**NOT SUPPORTED**")`
:::

::: column
**Effect size:** A 10% increase in traffic volume:

-   Changes odds of occurrence by `r round((exp(traffic_zero$Estimate * log(1.10)) - 1) * 100, 1)`%

-   Changes expected count by `r round((exp(traffic_count$Estimate * log(1.10)) - 1) * 100, 1)`%
:::
:::::

#### H2: Land Use Effects

::::: columns
::: column
##### H2a: Forest/Park habitat

Occurrence: p = `r forest_zero$P_value` `r forest_zero$Sig` \| Intensity: p = `r forest_count$P_value` `r forest_count$Sig`

Forest coverage `r ifelse(forest_zero$P_value < 0.05 | forest_count$P_value < 0.05, "significantly affects", "does not significantly affect")` roadkill patterns.
:::

::: column
##### H2b: Residential development

Occurrence: p = `r residential_zero$P_value` `r residential_zero$Sig` \| Intensity: p = `r residential_count$P_value` `r residential_count$Sig`

Residential areas show `r ifelse(residential_zero$Estimate < 0, "negative", "positive")` association (as predicted).
:::

H2 Status: `r ifelse((forest_zero$P_value < 0.05 | forest_count$P_value < 0.05) & (residential_zero$P_value < 0.05 | residential_count$P_value < 0.05), "**SUPPORTED**", "PARTIALLY SUPPORTED")`
:::::

#### H3: Road Characteristics

::::: columns
::: column
##### H3a: Minor roads (vs Major baseline)

Occurrence: p = `r minor_zero$P_value` `r minor_zero$Sig` \| Intensity: p = `r minor_count$P_value` `r minor_count$Sig`

Minor roads have `r ifelse(minor_zero$Estimate > 0, "higher", "lower")` roadkill rates than major roads.
:::

::: column
##### H3b: Speed limit

Occurrence: p = `r speed_zero$P_value` `r speed_zero$Sig` \| Intensity: p = `r speed_count$P_value` `r speed_count$Sig`

Speed limit `r ifelse(speed_zero$P_value < 0.05 | speed_count$P_value < 0.05, "significantly", "does not significantly")` affect `r ifelse(speed_zero$P_value < 0.05 | speed_count$P_value < 0.05, "s", "")` collision risk.
:::

H3 Status: `r ifelse((minor_zero$P_value < 0.05 | minor_count$P_value < 0.05) & (speed_zero$P_value < 0.05 | speed_count$P_value < 0.05), "**SUPPORTED**", "PARTIALLY SUPPORTED")`
:::::

------------------------------------------------------------------------

# 8. Discussion

### Summary of Findings

```{r}
#| label: summary-table-results
#| echo: false

summary_table <- tibble(
  Hypothesis = c("H1: Traffic", "H2a: Forest", "H2b: Residential", "H3a: Minor roads", "H3b: Speed"),
  Occurrence = c(
    ifelse(traffic_zero$P_value < 0.05, ifelse(traffic_zero$Estimate > 0, "+", "−"), "NS"),
    ifelse(forest_zero$P_value < 0.05, ifelse(forest_zero$Estimate > 0, "+", "−"), "NS"),
    ifelse(residential_zero$P_value < 0.05, ifelse(residential_zero$Estimate > 0, "+", "−"), "NS"),
    ifelse(minor_zero$P_value < 0.05, ifelse(minor_zero$Estimate > 0, "+", "−"), "NS"),
    ifelse(speed_zero$P_value < 0.05, ifelse(speed_zero$Estimate > 0, "+", "−"), "NS")
  ),
  Intensity = c(
    ifelse(traffic_count$P_value < 0.05, ifelse(traffic_count$Estimate > 0, "+", "−"), "NS"),
    ifelse(forest_count$P_value < 0.05, ifelse(forest_count$Estimate > 0, "+", "−"), "NS"),
    ifelse(residential_count$P_value < 0.05, ifelse(residential_count$Estimate > 0, "+", "−"), "NS"),
    ifelse(minor_count$P_value < 0.05, ifelse(minor_count$Estimate > 0, "+", "−"), "NS"),
    ifelse(speed_count$P_value < 0.05, ifelse(speed_count$Estimate > 0, "+", "−"), "NS")
  ),
  Support = c(
    ifelse(traffic_zero$P_value < 0.05 | traffic_count$P_value < 0.05, "✓", "✗"),
    ifelse(forest_zero$P_value < 0.05 | forest_count$P_value < 0.05, "✓", "✗"),
    ifelse(residential_zero$P_value < 0.05 | residential_count$P_value < 0.05, "✓", "✗"),
    ifelse(minor_zero$P_value < 0.05 | minor_count$P_value < 0.05, "✓", "✗"),
    ifelse(speed_zero$P_value < 0.05 | speed_count$P_value < 0.05, "✓", "✗")
  )
)

knitr::kable(summary_table, caption = "Hypothesis Test Results (+ positive effect, − negative effect, NS not significant; baseline: Major roads)")
```

### Policy Implications

Our findings suggest several evidence-based mitigation strategies:

1.  **Traffic management**: Roads with AADT \> `r format(quantile(model_data$AADT, 0.75, na.rm = TRUE), big.mark = ",")` vehicles/day (75th percentile) near natural habitats are high-priority for wildlife warning systems

2.  **Targeted interventions**: Focus mitigation efforts (wildlife crossings, fencing) on:

-   High-traffic corridors adjacent to forests/parks

-   Major highways with speed limits ≥80 km/h

-   Areas where predicted collision probability exceeds threshold

3.  **Land use planning**: Consider roadkill risk when approving development near wildlife habitat

### Limitations

1.  **Spatial coverage.** The analysis includes only roads near traffic counters (about 75% of the network). Low-traffic and rural roads may be underrepresented.

2.  **Species grouping.** All species are combined into one outcome. This hides differences in behavior and risk between species.

3.  **Timing differences across datasets.** Road data are from 2024, traffic data from 2019, and crash records from 2017–2019. Seasonal and daily patterns are not modeled, and these timing differences may add error.

4.  **Missing variables.** The model does not include direct data on animal population size, movement, road features (such as fencing and lighting), or driver behavior. These factors could affect collision risk and may influence the results.

5.  **Reporting bias.** Not all collisions are reported, and reporting likely differs by location. Rural areas in particular may appear safer simply because fewer events are recorded.

6.  **Spatial clustering.** Collisions tend to cluster in certain areas, but this spatial pattern is not explicitly modeled. This may lead to uncertainty being understated.

7.  **Interpretation.** Results show associations, not cause-and-effect. Land use is used as a stand-in for animal presence, and traffic estimates are imperfect.

#### Conclusions

This analysis demonstrates how hurdle models handle zero-inflated ecological count data by separately modeling occurrence and intensity processes. We identified traffic volume, land use composition, and road characteristics as key predictors of wildlife-vehicle collisions on Danish roads.

Key contributions:

-   Methodological framework for zero-inflated spatial count data

-   Quantified effects of infrastructure and landscape on roadkill risk

-   Policy-relevant findings for targeted mitigation

The hurdle model approach extends beyond roadkill to any ecological phenomenon with excess zeros: rare species observations, disease outbreaks, extreme weather events, or pollution violations.

------------------------------------------------------------------------

## References

::: {#refs}
:::

