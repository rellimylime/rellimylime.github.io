---
title: "Traffic, Land Use, and Wildlife-Vehicle Collisions in Denmark"
description: "Using a hurdle model to understand roadkill patterns on Danish roads"
author: Emily Miller
date: 2025-11-29
categories: [MEDS, R, Statistics, Wildlife]
image: eds222-final-cover.jpg
citation:
  url: https://rellimylime.github.io/posts/eds222-final/
bibliography: references.bib
output: 
  html_document:
    code_download: true
execute:
  eval: true
  echo: true
  warning: false
  message: false
---

# 1. Introduction: Why This Matters

Wildlife-vehicle collisions threaten biodiversity and pose safety risks. Understanding which road and landscape characteristics predict roadkill hotspots enables evidence-based mitigation. We analyze \~11,000 roadkill events on 241,000 Danish road segments (2017-2019) to test whether traffic volume, forest proximity, and urban development predict collision rates.

**The puzzle**: Some roads experience frequent wildlife collisions while others have zero incidents. Is it just random chance or collection bias? Or are there systematic patterns we can identify and address?

If we can predict which roads are most likely to become collision hotspots, transportation planners and conservationists can install wildlife crossings, implement warning systems, or adjust speed limits in high-risk areas.

### **Research Question**

**How do traffic volume and land use characteristics affect wildlife-vehicle collisions on Danish roads?**

Specifically, we investigate two processes:

1.  **Occurrence**: What makes roadkill more likely to happen at all on a given road segment?
2.  **Intensity**: Once roadkill does occur, what factors influence how many collision events happen?

The high proportion of road segments with zero observed roadkill (\~83%) suggests these processes operate differently, making a hurdle model the appropriate statistical framework.

# 2. Building a Theory: What Causes Roadkill?

### **The Causal Story**

Imagine you're a deer deciding whether to cross a road. Several factors affect your collision risk:

1.  **Traffic volume**: More vehicles = more chances for collision
2.  **Your habitat**: You're more likely to be near roads that pass through forests or parks
3.  **Road characteristics**: Wider, faster roads are harder to cross safely
4.  **Human development**: You avoid heavily urbanized areas

### **Visualizing Causal Relationships: The DAG**

Now, let's formalize our deer's decision-making process with a Directed Acyclic Graph (DAG).

```{r}
#| label: aesthetics
#| include: false

# Define colors to match my website
primary_color <- "#2A9D8F"
accent_color <- "#E76F51"
neutral_color <- "#6A4C93"
text_dark <- "#2B2D42"
text_mid <- "#5A5A5A"
bg_warm <- "#FFFEF9"

# DAG libraries
library(ggdag)
library(dagitty)
library(tidyverse)

# Unified theme for all plots
theme_cohesive <- function() {
  theme_minimal() +
    theme(
      text = element_text(color = text_dark),
      plot.title = element_text(size = 14, face = "bold", color = text_dark),
      plot.subtitle = element_text(size = 11, color = text_mid),
      plot.background = element_rect(fill = bg_warm, color = NA),
      panel.background = element_rect(fill = bg_warm, color = NA),
      panel.grid.major = element_line(color = "#E5E5E5", linewidth = 0.3),
      panel.grid.minor = element_blank(),
      axis.text = element_text(color = text_mid),
      axis.title = element_text(color = text_dark, face = "bold")
    )
}

```

```{r}
#| label: dag
#| fig-width: 8
#| fig-height: 6
#| echo: false

# Define DAG
roadkill_dag <- dagify(
  Roadkill ~ Traffic + LandUse + RoadType + Speed,
  Traffic ~ RoadType + LandUse,
  Speed ~ RoadType,
  RoadType ~ LandUse,
  outcome = "Roadkill",
  labels = c(
    "Roadkill" = "Roadkill",
    "Traffic" = "Traffic\nVolume",
    "LandUse" = "Land\nUse",
    "RoadType" = "Road\nType",
    "Speed" = "Speed\nLimit"
  ),
  coords = list(
    x = c(Traffic = 1, RoadType = 1, Speed = 2, LandUse = 2, Roadkill = 3),
    y = c(Traffic = 2, RoadType = 1, Speed = 1, LandUse = 2, Roadkill = 1.5)
  )
)

# Prepare for plotting with labels
dag_tidy <- roadkill_dag %>% 
  tidy_dagitty() %>%
  mutate(
    color_group = case_when(
      name == "Roadkill" ~ "outcome",
      TRUE ~ "other"
    )
  )

# Plot with custom styling
ggplot(dag_tidy, aes(x = x, y = y, xend = xend, yend = yend)) +
  # Edges
  geom_dag_edges(
    edge_width = 0.8,
    arrow_directed = grid::arrow(length = unit(10, "pt"), type = "closed"),
    edge_color = text_mid
  ) +
  # Nodes with colors
  geom_dag_point(
    aes(color = color_group),
    size = 20,
    show.legend = FALSE
  ) +
  # Text labels
  geom_dag_text(
    aes(label = label),
    color = "white",
    size = 3.5,
    fontface = "bold",
    family = "sans"
  ) +
  # Color scheme
  scale_color_manual(
    values = c(
      "outcome" = accent_color,
      "other" = neutral_color
    )
  ) +
  # Theme
  theme_dag() +
  labs(
    title = "Causal Diagram: Factors Influencing Wildlife-Vehicle Collisions"
  ) +
  theme(
    plot.title = element_text(
      size = 14, 
      face = "bold", 
      color = text_dark,
      hjust = 0.5
    ),
    plot.background = element_rect(fill = bg_warm, color = NA),
    panel.background = element_rect(fill = bg_warm, color = NA)
  )
```

**Key relationships:**

-   **Traffic (AADT)** directly affects roadkill probability (more vehicles → more collision opportunities)
-   **Land use** influences wildlife presence near roads (forests/parks attract wildlife) as well as road types
-   **Road type** is a common cause affecting traffic volume, and speed limits
-   **Speed limit** affects collision severity and driver reaction time
-   We control for **road type** to avoid confounding when estimating traffic effects

**NOTE**: Without considering wildlife density and surrounding habitats, this model estimates relationships conditional on unobserved wildlife presence, which is approximated using nearby land-use rather than direct population data.

------------------------------------------------------------------------

# 3. Hypothesis

Based on our causal theory, we make three sets of predictions:

| Hypothesis | Variable | Expected Effect | Rationale |
|------------------|------------------|-------------------|------------------|
| **H1: Traffic** | AADT (↑) | \+ occurrence, + intensity | More vehicles → more collision opportunities |
| **H2a: Wildlife habitat** | Forest/Park (↑) | \+ occurrence, + intensity | Attracts wildlife near roads |
| **H2b: Urban development** | Residential (↑) | \- occurrence, - intensity | Reduces wildlife presence |
| **H3a: Road infrastructure** | Major roads | \+ occurrence, + intensity | Higher speeds, more lanes |
| **H3b: Speed** | Speed limit (↑) | \+ occurrence, + intensity | Reduced reaction time, higher mortality |

We'll test this in *both* parts of our model:

**Note:** All effects are interpreted as rates per km (controlled via offset for road length).

------------------------------------------------------------------------

# 4. Data & Methods

### Data Sources

| Dataset | Source | Variables | Coverage |
|------------------|------------------|-------------------|------------------|
| Roadkill observations | Global Roadkill Database [@grilo2025] | GPS coordinates, species | 2017-2019 |
| Road network | OpenStreetMap [@osm2024] | Geometry, type, speed limits | Denmark |
| Traffic counts | Danish Road Directorate [@vejdirektoratet2019] | AADT (vehicles/day) | Monitoring stations |
| Land use | OpenStreetMap [@osm2024] | Forest, farmland, residential, parks | 500m buffers |

Technical Setup: \[`tidyverse`, `sf`, `terra`, `here`, `pscl`, `yaml`, `patchwork`, `dagitty`, `ggdag`\]

```{r}
#| label: setup
#| code-fold: true

library(tidyverse)
library(sf)
library(terra)
library(here)
library(pscl)
library(yaml)
library(patchwork)

# Load configuration
config <- read_yaml(here("posts/eds222-final/config.yml"))

set.seed(config$seed)

CRS_M <- config$crs # EPSG:25832, Denmark ETRS89 / UTM zone 32N

# Denmark bounding box (WGS84)
dk_bbox_wgs84 <- st_bbox(c(
  xmin = config$bbox_xmin,
  ymin = config$bbox_ymin,
  xmax = config$bbox_xmax,
  ymax = config$bbox_ymax
), crs = config$bbox_crs)

# Transform to projected CRS
dk_bbox_proj <- st_transform(st_as_sfc(dk_bbox_wgs84), CRS_M) %>%
  st_bbox()
```

#### Load Roadkill Observations

Roadkill observations are GPS point locations filtered to Denmark and the study period (2017-2019), then transformed to a projected coordinate system (EPSG:4326) for analysis.

```{r}
#| label: load-roadkill
#| code-fold: true

# Load roadkill CSV
road_kill_dk <- read_csv(here(config$roadkill_csv_path)) %>%
    filter(
        country == "Denmark",
        year >= 2017, year <= 2019
    ) %>%
    drop_na(decimalLongitude, decimalLatitude) %>%
    st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) %>%
    st_transform(CRS_M) %>%
    st_crop(dk_bbox_proj)
```

> -   Roadkill observations: `r format(nrow(road_kill_dk), big.mark = ",")`
> -   Time period: 2017-2019
> -   Coordinate system: ETRS89 / UTM zone 32N

#### Load Road Network

```{r}
#| label: load-roads-cached
#| code-fold: true
#| output: false

# Define cache path for roads data
roads_cache <- here(config$roads_cached_path)

if (file.exists(roads_cache)) {
  cat("Loading roads from cache...\n")
  roads_raw <- readRDS(roads_cache)
} else {
  cat("Cache not found. Loading and processing roads (one-time setup)...\n")

  # Load shapefile
  roads_raw <- st_read(here(config$roads_shp_path), quiet = TRUE) %>%
    st_transform(CRS_M) %>%
    st_crop(dk_bbox_proj)

  # Save to cache
  cat("Saving roads to cache for future runs...\n")
  saveRDS(roads_raw, roads_cache)
  cat("Cache saved:", roads_cache, "\n")
}
```

> Road segments loaded: `r format(nrow(roads_raw), big.mark = ",")`

#### Load Traffic Data

Traffic counts represent Annual Average Daily Traffic (AADT) from monitoring stations, averaged across 2017-2019.

```{r}
#| label: load-traffic-cached
#| code-fold: true
#| output: false

# Define cache path for traffic data
traffic_cache <- here(config$traffic_cached_path)

if (file.exists(traffic_cache)) {
  cat("Loading traffic data from cache...\n")
  traffic_raw <- readRDS(traffic_cache)
} else {
  cat("Cache not found. Loading and processing traffic (one-time setup)...\n")

  # Load shapefile
  traffic_raw <- st_read(here(config$traffic_shp_path), quiet = TRUE) %>%
  st_transform(CRS_M) %>%
  st_crop(dk_bbox_proj) %>%
  filter(AAR >= 2017, AAR <= 2019) %>%
  # Average AADT across years for each station
  group_by(geometry) %>%
  summarise(
    AADT = mean(AADT, na.rm = TRUE),
    AAR = "2017-2019",
    .groups = "drop"
  ) %>%
  st_as_sf()

  # Save to cache
  cat("Saving traffic to cache for future runs...\n")
  saveRDS(traffic_raw, traffic_cache)
  cat("Cache saved:", traffic_cache, "\n")
}

```

> Traffic monitoring stations: `r format(nrow(traffic_raw), big.mark = ",")`

#### Load Land Use Data

Land use polygons classify areas as forest, farmland, residential, parks, etc.

```{r}
#| label: load-landuse-cached
#| code-fold: true
#| include: false

# Define cache path for traffic data
landuse_cache <- here(config$landuse_cached_path)

if (file.exists(landuse_cache)) {
  cat("Loading land use from cache...\n")
  landuse_raw <- readRDS(landuse_cache)
} else {
  cat("Cache not found. Loading and processing land use (one-time setup)...\n")

  # Load shapefile
  landuse_raw <- st_read(here(config$landuse_shp_path), quiet = TRUE) %>%
    st_transform(CRS_M) %>%
    st_crop(dk_bbox_proj)

  # Save to cache
  cat("Saving land use to cache for future runs...\n")
  saveRDS(landuse_raw, landuse_cache)
  cat("Cache saved:", landuse_cache, "\n")
}

cat("Land use polygons loaded:", format(nrow(landuse_raw), big.mark = ","), "\n")
```

> Land use polygons: `r format(nrow(landuse_raw), big.mark = ",")`

```{r}
#| label: explore-landuse-classes
#| include: false
#| code-fold: true

# Explore land use classes
landuse_summary <- landuse_raw %>%
  st_drop_geometry() %>%
  count(fclass, sort = TRUE) %>%
  filter(!is.na(fclass))

cat("\nTop land use classes:\n")
print(head(landuse_summary, 10))
```

Top land use classes:

```{r}
#| label: show-landuse-summary
#| echo: false
knitr::kable(head(landuse_summary, 10), caption = "Top 10 Land Use Classes")
```

**Computational Note**: These shapefiles are large (millions of features); we cache the processed/projected versions to avoid reloading and processing during every run. First runs take \~5-10 minutes each; cached runs take seconds.

------------------------------------------------------------------------

### Data Processing Pipeline

#### Filter to Motorized Roads

We restrict analysis to roads accessible by motor vehicles, excluding pedestrian paths and cycleways and other places where wildlife-vehicle collisions cannot occur.

```{r}
#| label: filter-roads
#| code-fold: true
#| include: false

# Extract car codes from config
car_codes <- c(
  config$road_car_codes_major,
  config$road_car_codes_minor,
  config$road_car_codes_links
)

# Filter and calculate road lengths
car_roads <- roads_raw %>%
  filter(code %in% car_codes) %>%
  mutate(
    len_m = st_length(geometry),
    len_km = as.numeric(len_m) / 1000
  )

cat("Car-accessible roads:\n")
cat("  Segments:", format(nrow(car_roads), big.mark = ","), "\n")
cat("  Total length:", format(round(sum(car_roads$len_km), 0), big.mark = ","), "km\n")
cat("  Mean segment length:", round(mean(car_roads$len_km), 2), "km\n\n")
```

> -   Motorized road segments: `r format(nrow(car_roads), big.mark = ",")`
> -   Total road length: `r format(round(sum(car_roads$len_km)), big.mark = ",")` km
> -   Mean segment length: `r round(mean(car_roads$len_km), 2)` km

#### Match Traffic to Road Segments

Traffic monitoring stations are point locations. Since there are far more roads than monitoring stations, I assigned each road segment with the AADT from its nearest station, applying a distance threshold. This means we only assign traffic data to roads within \~3.7 km of a monitoring station, avoiding matches to stations that are unreasonably far away. This balances **coverage** (75% of roads get traffic data) with **accuracy** (avoiding spurious long-distance matches).

```{r}
#| label: match-traffic
#| code-fold: true
#| include: false

# Define cache path for distance data
distances_cache_file <- here(config$distances_cache_path)

if (file.exists(distances_cache_file)) {
  cat("Loading cached distances...\n")
  distances_data <- readRDS(distances_cache_file)
  nearest_idx <- distances_data$nearest_idx
  distances <- distances_data$distances
} else {
  cat("Computing road-to-traffic distances (one-time calculation, ~5-10 min)...\n")

  # Prepare traffic data - select only needed columns
  traffic_trim <- traffic_raw %>%
    dplyr::select(AAR, AADT, geometry)

  # Find nearest traffic point to each road
  nearest_idx <- st_nearest_feature(car_roads, traffic_trim)

  # Calculate distances
  distances <- st_distance(car_roads, traffic_trim[nearest_idx, ], by_element = TRUE)

  # Save both for next time
  saveRDS(list(nearest_idx = nearest_idx, distances = distances),
          distances_cache_file)
  cat("Distances cached:", distances_cache_file, "\n")
}

cat("Distance matching complete.\n\n")
```

```{r}
#| label: apply-threshold
#| code-fold: true

# Apply configured threshold
threshold_percentile <- config$distance_threshold_percentile
dist_threshold <- quantile(as.numeric(distances), threshold_percentile)

# Merge traffic data with roads
roads_traf <- car_roads %>%
  mutate(
    nn_dist_m = as.numeric(distances),
    AADT = if_else(nn_dist_m <= dist_threshold,
                   traffic_raw$AADT[nearest_idx],
                   NA_real_)
  )
```

> -   Distance threshold: `r format(round(dist_threshold), big.mark = ",")` m (75th percentile)
> -   Roads with traffic data: `r format(sum(!is.na(roads_traf$AADT)), big.mark = ",")` (`r round(mean(!is.na(roads_traf$AADT)) * 100, 1)`%)
> -   AADT range: `r format(min(roads_traf$AADT, na.rm = TRUE), big.mark = ",")` - `r format(max(roads_traf$AADT, na.rm = TRUE), big.mark = ",")` vehicles/day

**Note**: Analysis is limited to Denmark's *monitored* road network (major highways and urban roads). Remote rural roads are likely not included.

------------------------------------------------------------------------

#### Extract Land Use Around Roads

We calculate the percentage of forest, farmland, residential, and park land use within 500m buffers around each road segment. This distance approximates wildlife movement ranges and habitat edge effects.

```{r}
#| label: extract-landuse
#| code-fold: true
#| include: false

# Define cache path for landuse data
landuse_cache_file <- here(config$landuse_props_path)

if (file.exists(landuse_cache_file)) {
  cat("Loading cached land use proportions...\n")
  lu_props <- readRDS(landuse_cache_file)
} else {
  cat("Extracting land use via RASTER...\n\n")
  
  library(terra)
  
  # Rasterize land use
  cat("Converting land use to raster (~2-3 min)...\n")
  
  # Get extent from roads
  roads_extent <- st_bbox(roads_traf) %>% st_as_sfc() %>% st_buffer(1000)
  
  # Create raster template (100m resolution)
  rast_template <- rast(
    ext(vect(roads_extent)),
    resolution = 100,
    crs = crs(vect(roads_traf))
  )
  
  cat("  Rasterizing", nrow(landuse_raw), "polygons...\n")
  
  # Convert fclass to numeric codes for rasterization
  landuse_coded <- landuse_raw %>%
    mutate(fclass_num = as.numeric(as.factor(fclass)))
  
  fclass_lookup <- landuse_coded %>%
    st_drop_geometry() %>%
    distinct(fclass, fclass_num)
  
  # Rasterize
  landuse_raster <- rasterize(
    vect(landuse_coded),
    rast_template,
    field = "fclass_num"
  )
  
  cat("  Raster created.\n\n")
  
  # Extract for road buffers
  cat("Extracting land use for road buffers...\n")
  
  roads_with_id <- roads_traf %>%
    mutate(road_id = row_number())
  
  road_buffers <- roads_with_id %>%
    st_buffer(config$road_buffer_distance) %>%
    dplyr::select(road_id)
  
  cat("  Extracting raster values (this takes 2-5 min)...\n")
  
  # Extract all raster cells within each buffer
  extracted <- extract(landuse_raster, vect(road_buffers), fun = NULL)
  
  cat("  Extraction complete. Calculating proportions...\n")
  
  # Calculate proportions
  landuse_props <- extracted %>%
    as_tibble() %>%
    rename(road_id = ID, fclass_num = 2) %>%
    filter(!is.na(fclass_num)) %>%
    left_join(fclass_lookup, by = "fclass_num") %>%
    count(road_id, fclass) %>%
    group_by(road_id) %>%
    mutate(pct = n / sum(n) * 100) %>%
    ungroup() %>%
    dplyr::select(road_id, fclass, pct) %>%
    pivot_wider(
      names_from = fclass,
      values_from = pct,
      values_fill = 0,
      names_prefix = "pct_"
    )
  
  # Add missing columns with 0 before combining
  lu_props <- landuse_props
  
  if (!"pct_forest" %in% names(lu_props)) lu_props$pct_forest <- 0
  if (!"pct_scrub" %in% names(lu_props)) lu_props$pct_scrub <- 0
  if (!"pct_farmland" %in% names(lu_props)) lu_props$pct_farmland <- 0
  if (!"pct_farmyard" %in% names(lu_props)) lu_props$pct_farmyard <- 0
  if (!"pct_meadow" %in% names(lu_props)) lu_props$pct_meadow <- 0
  if (!"pct_orchard" %in% names(lu_props)) lu_props$pct_orchard <- 0
  if (!"pct_vineyard" %in% names(lu_props)) lu_props$pct_vineyard <- 0
  if (!"pct_residential" %in% names(lu_props)) lu_props$pct_residential <- 0
  if (!"pct_park" %in% names(lu_props)) lu_props$pct_park <- 0
  if (!"pct_nature_reserve" %in% names(lu_props)) lu_props$pct_nature_reserve <- 0
  if (!"pct_recreation_ground" %in% names(lu_props)) lu_props$pct_recreation_ground <- 0
  if (!"pct_grass" %in% names(lu_props)) lu_props$pct_grass <- 0
  
  # Combine related land use types
  lu_props <- lu_props %>%
    mutate(
      pct_forest = pct_forest + pct_scrub,
      pct_farmland = pct_farmland + pct_farmyard + pct_meadow + pct_orchard + pct_vineyard,
      pct_residential = pct_residential,
      pct_park = pct_park + pct_nature_reserve + pct_recreation_ground + pct_grass
    ) %>%
    dplyr::select(road_id, pct_forest, pct_farmland, pct_residential, pct_park)
  
  # Fill missing roads with 0
  complete_roads <- tibble(road_id = 1:nrow(roads_traf))
  
  lu_props <- complete_roads %>%
    left_join(lu_props, by = "road_id") %>%
    mutate(across(starts_with("pct_"), ~ replace_na(., 0)))
  
  saveRDS(lu_props, landuse_cache_file)
  cat("\nCache saved\n")
}


cat("Roads with land use data:", format(nrow(lu_props), big.mark = ","), "\n")
cat("Mean % Forest:", round(mean(lu_props$pct_forest), 1), "%\n")
cat("Mean % Farmland:", round(mean(lu_props$pct_farmland), 1), "%\n")
cat("Mean % Residential:", round(mean(lu_props$pct_residential), 1), "%\n")
cat("Mean % Park:", round(mean(lu_props$pct_park), 1), "%\n")
```

Mean land use composition within 500m:

> -   Forest: `r round(mean(lu_props$pct_forest), 1)`%
> -   Farmland: `r round(mean(lu_props$pct_farmland), 1)`%
> -   Residential: `r round(mean(lu_props$pct_residential), 1)`%
> -   Parks: `r round(mean(lu_props$pct_park), 1)`%

#### Aggregate Roadkill by Road Segment

Each roadkill point is matched to its nearest road segment using spatial join.

```{r}
#| label: aggregate-roadkill
#| code-fold: true
#| include: false

# Define cache path for aggregated roadkill data
roadkill_cache_file <- here(config$roadkill_cache_path)

if (file.exists(roadkill_cache_file)) {
  cat("Loading cached roadkill aggregation...\n")
  roadkill_by_segment <- readRDS(roadkill_cache_file)
} else {
  cat("Computing roadkill aggregation (spatial join, ~2-5 min)...\n")

  # Spatial join: roadkill points to nearest road
  roadkill_by_segment <- road_kill_dk %>%
    st_join(roads_traf %>% dplyr::select(osm_id),
            join = st_nearest_feature) %>%
    group_by(osm_id) %>%
    summarise(roadkill_count = n(), .groups = "drop") %>%
    st_drop_geometry()

  saveRDS(roadkill_by_segment, roadkill_cache_file)
  cat("Cache saved:", roadkill_cache_file, "\n")
}

cat("Roadkill aggregation complete.\n")
cat("  Unique road segments with roadkill:",
    format(nrow(roadkill_by_segment), big.mark = ","), "\n\n")
```

> -   Road segments with roadkill: `r format(nrow(roadkill_by_segment), big.mark = ",")`

#### Create Final Analysis Dataset

We merge all data sources and apply transformations required for modeling: log-transform traffic and road length, classify road types, and assign missing speed limits.

```{r}
#| label: create-model-data
#| code-fold: true
#| include: false

# Merge all data sources
model_data <- roads_traf %>%
  st_drop_geometry() %>%
  mutate(road_id = row_number()) %>%
  left_join(roadkill_by_segment, by = "osm_id") %>%
  left_join(lu_props, by = "road_id") %>%
  replace_na(list(roadkill_count = 0)) %>%
  # Fill missing land use with 0
  mutate(across(starts_with("pct_"), ~ replace_na(., 0))) %>%
  filter(!is.na(AADT), AADT > 0) %>%
  mutate(
    # Log transforms for modeling
    log_AADT = log(AADT),
    log_len_km = log(len_km),

    # Road type classification
    road_type = case_when(
      code %in% config$road_car_codes_major ~ "Major",
      code %in% config$road_car_codes_minor ~ "Minor",
      code %in% config$road_car_codes_links ~ "Links/Ramps",
      TRUE ~ "Other"
    ),

    # Speed limit (convert to numeric, impute missing with median)
    speed_limit = as.numeric(maxspeed),
    speed_limit = if_else(is.na(speed_limit),
                          median(speed_limit, na.rm = TRUE),
                          speed_limit)
  )

cat("Total segments:", format(nrow(model_data), big.mark = ","), "\n")
cat("Segments with roadkill:",
    format(sum(model_data$roadkill_count > 0), big.mark = ","),
    "(", round(mean(model_data$roadkill_count > 0) * 100, 1), "%)\n")
cat("Zero-inflation rate:",
    round(mean(model_data$roadkill_count == 0) * 100, 1), "%\n")
cat("Mean roadkill per segment:", round(mean(model_data$roadkill_count), 3), "\n")
cat("Variance:", round(var(model_data$roadkill_count), 3), "\n")
cat("Variance/Mean ratio (dispersion):",
    round(var(model_data$roadkill_count) / mean(model_data$roadkill_count), 2), "\n")
cat("Total roadkill events:", format(sum(model_data$roadkill_count), big.mark = ","), "\n\n")
```

```{r}
#| label: dataset-summary
#| echo: false

summary_stats <- tibble(
  Metric = c(
    "Road segments",
    "Segments with roadkill",
    "Zero-inflation rate",
    "Total roadkill events",
    "Mean roadkill per segment",
    "Overdispersion (Var/Mean)"
  ),
  Value = c(
    format(nrow(model_data), big.mark = ","),
    paste0(format(sum(model_data$roadkill_count > 0), big.mark = ","), 
           " (", round(mean(model_data$roadkill_count > 0) * 100, 1), "%)"),
    paste0(round(mean(model_data$roadkill_count == 0) * 100, 1), "%"),
    format(sum(model_data$roadkill_count), big.mark = ","),
    round(mean(model_data$roadkill_count), 3),
    round(var(model_data$roadkill_count) / mean(model_data$roadkill_count), 2)
  )
)

knitr::kable(summary_stats, caption = "Final Dataset Characteristics")
```

**Key observations**:

> -   High zero-inflation (`r round(mean(model_data$roadkill_count == 0) * 100, 1)`%) justifies hurdle model
> -   Overdispersion (Var/Mean = `r round(var(model_data$roadkill_count) / mean(model_data$roadkill_count), 2)`) justifies negative binomial distribution

------------------------------------------------------------------------

# 5. Exploratory Analysis

::: panel-tabset
```{r}
#| label: eda-plots
#| echo: false
#| fig-width: 14
#| fig-height: 10

library(patchwork)

# Plot 1: Distribution histogram
p1 <- ggplot(model_data, aes(x = roadkill_count)) +
  geom_histogram(binwidth = 1, fill = primary_color, color = text_dark, alpha = 0.8) +
  scale_y_continuous(labels = scales::comma) +
  labs(
    title = "A. Distribution of Roadkill Counts",
    subtitle = "High zero-inflation evident",
    x = "Roadkill Events per Segment", 
    y = "Frequency"
  ) +
  theme_cohesive()

# Plot 2: Traffic volume
p2 <- ggplot(model_data, aes(x = AADT, y = roadkill_count)) +
  geom_hex(bins = 50, alpha = 0.8) +
  geom_smooth(method = "loess", color = accent_color, fill = accent_color, 
              se = TRUE, alpha = 0.3, linewidth = 1.2) +
  scale_x_log10(labels = scales::comma) +
  scale_fill_gradient(low = bg_warm, high = neutral_color, 
                      name = "Count", trans = "log10") +
  labs(
    title = "B. Roadkill vs Traffic Volume",
    subtitle = "Positive relationship visible",
    x = "AADT (log scale, vehicles/day)", 
    y = "Roadkill Count"
  ) +
  theme_cohesive() +
  theme(legend.position = "right")

# Plot 3: Boxplot by road type (this one is fine but needs better colors)
p3 <- ggplot(model_data %>% filter(roadkill_count > 0),
             aes(x = road_type, y = roadkill_count, fill = road_type)) +
  geom_boxplot(alpha = 0.7, show.legend = FALSE, outlier.alpha = 0.3) +
  scale_fill_manual(values = c(
    "Major" = accent_color,
    "Minor" = primary_color,
    "Links/Ramps" = neutral_color,
    "Other" = text_mid
  )) +
  scale_y_log10() +
  labs(
    title = "C. Roadkill by Road Type",
    subtitle = "Among segments with at least one event",
    x = "Road Classification", 
    y = "Roadkill Count (log scale)"
  ) +
  theme_cohesive()

# Plot 4: Road length - ALSO use hexbin
p4 <- ggplot(model_data, aes(x = len_km, y = roadkill_count)) +
  geom_hex(bins = 50, alpha = 0.8) +
  geom_smooth(method = "loess", color = neutral_color, fill = neutral_color,
              se = TRUE, alpha = 0.3, linewidth = 1.2) +
  scale_x_log10() +
  scale_fill_gradient(low = bg_warm, high = primary_color, 
                      name = "Count", trans = "log10") +
  labs(
    title = "D. Roadkill vs Road Length",
    subtitle = "Longer segments have more events",
    x = "Segment Length (km, log scale)", 
    y = "Roadkill Count"
  ) +
  theme_cohesive() +
  theme(legend.position = "right")

# Combine plots
# (p1 + p2) / (p3 + p4)
```

## Visualizations

![](eda_visualization_themed.png)

## Key patterns

1.  **Panel A (distribution)**: Massive spike at zero confirms zero-inflation—most roads never experience roadkill
2.  **Panel B (traffic effect)**: Clear positive trend—higher AADT associates with more roadkill
3.  **Panel C (road type)**: Major roads show higher roadkill intensity than minor roads (conditional on having any)
4.  **Panel D (road length)**: Longer segments have more events, confirming we need a length offset
:::

These patterns validate our hypotheses from the DAG. Now let's build a statistical model to quantify these effects.





------------------------------------------------------------------------

# 6. Statistical Model: The Hurdle Approach

### Why a Hurdle Model?

Traditional count models (Poisson, negative binomial) underestimate zeros. Our data exhibits:

-   Excess zeros: `r round(mean(model_data$roadkill_count == 0) * 100, 1)`% of segments have no roadkill

-   Overdispersion: Variance (`r round(var(model_data$roadkill_count), 2)`) \>\> Mean (`r round(mean(model_data$roadkill_count), 3)`)

A **hurdle model** separates two processes:

1.  **Binary hurdle** (logistic): Does roadkill occur at all?
2.  **Count component** (negative binomial): How many events, given occurrence?

### Model Specification

$$
P(Y_i = y) = \begin{cases}
\pi_i & \text{if } y = 0 \\
(1 - \pi_i) \cdot f_{\text{NB}}(y; \mu_i, \theta) & \text{if } y > 0
\end{cases}
$$

Zero component (logistic regression): $\text{logit}(\pi_i) = \alpha_0 + \alpha_1 \log(\text{AADT}_i) + \alpha_2 \text{RoadType}_i + \alpha_3 \text{Speed}_i + \alpha_4 \text{LandUse}_i$

Count component (negative binomial): $\log(\mu_i) = \beta_0 + \beta_1 \log(\text{AADT}_i) + \beta_2 \text{RoadType}_i + \beta_3 \text{Speed}_i + \beta_4 \text{LandUse}_i + \log(\text{length}_i)$

Where $\log$(\text{length}$_i$) is an offset controlling for road exposure.

#### Model Validation: Simulation Test

Before applying to real data, we verify the model recovers known parameters from simulated data.

```{r}
#| label: simulate-hurdle
#| code-fold: true

set.seed(42)
n_sim <- 1000
x_sim <- rnorm(n_sim, mean = 10, sd = 2)

# True parameters for pscl::hurdle
# Zero component: models P(Y > 0) in logit scale
# Positive coefficient = higher x → higher P(Y > 0) → MORE roadkill
beta0_zero <- 0.5   
beta1_zero <- 0.3   

# Count component: models E[Y | Y > 0] in log scale  
beta0_count <- 1.0
beta1_count <- 0.15
theta <- 2.0

# Generate the zero hurdle: P(Y > 0)
logit_prob_nonzero <- beta0_zero + beta1_zero * x_sim
prob_nonzero <- plogis(logit_prob_nonzero)

# Initialize output
y_sim <- rep(0, n_sim)

# For each observation
for (i in 1:n_sim) {
  # Step 1: Does the hurdle succeed? (Is Y > 0?)
  hurdle_success <- rbinom(1, size = 1, prob = prob_nonzero[i])
  
  if (hurdle_success == 1) {
    # Step 2: Generate truncated count (Y | Y > 0)
    lambda_i <- exp(beta0_count + beta1_count * x_sim[i])
    repeat {
      y_candidate <- rnbinom(1, mu = lambda_i, size = theta)
      if (y_candidate > 0) {
        y_sim[i] <- y_candidate
        break
      }
    }
  }
  # else: y_sim[i] stays 0
}

sim_data <- tibble(x = x_sim, y = y_sim)
```

Simulated data characteristics:

> -   Zero rate: `r round(mean(sim_data$y == 0) * 100, 1)`%
> -   Mean count (all): `r round(mean(sim_data$y), 3)`
> -   Mean count (non-zero only): `r round(mean(sim_data$y[sim_data$y > 0]), 3)`

```{r}
#| label: fit-simulated
#| code-fold: true

# Fit hurdle model to simulated data
sim_hurdle <- hurdle(y ~ x, data = sim_data, dist = "negbin")

# Extract estimated parameters
sim_coefs <- coef(sim_hurdle)

```

#### Parameter recovery check

```{r}
#| label: parameter-recovery
#| echo: false

recovery_table <- tibble(
  Component = c("Zero", "Zero", "Count", "Count"),
  Parameter = c("Intercept", "Slope", "Intercept", "Slope"),
  `True Value` = c(beta0_zero, beta1_zero, beta0_count, beta1_count),
  Estimated = round(sim_coefs[1:4], 3),
  Difference = round(sim_coefs[1:4] - c(beta0_zero, beta1_zero, beta0_count, beta1_count), 3)
) %>%
  mutate(Recovered = ifelse(abs(Difference) < 0.2, "✓", "✗"))

knitr::kable(recovery_table, 
             caption = "Parameter Recovery Check: Simulated Data",
             digits = 3)
```

Conclusion: Model successfully recovers known parameters (differences \< 0.2). We can apply it to real data with confidence.

```{r}
#| label: sim-visualization
#| code-fold: true
#| fig-width: 10
#| fig-height: 4

# Create prediction grid
x_grid <- seq(min(sim_data$x), max(sim_data$x), length.out = 100)
pred_data <- tibble(x = x_grid)

# Get hurdle model predictions
# type = "zero" returns P(Y > 0) directly (NOT P(Y = 0)!)
pred_data$prob_nonzero <- predict(sim_hurdle, newdata = pred_data, type = "zero")

# Expected count given non-zero
pred_data$count_given_nonzero <- predict(sim_hurdle, newdata = pred_data, type = "count")

# Plot 1: Zero hurdle component
p_sim1 <- ggplot() +
  # Add binned proportions to show empirical pattern
  stat_summary_bin(
    data = sim_data,
    aes(x = x, y = as.numeric(y > 0)),
    fun = mean,
    geom = "point",
    bins = 20,
    color = primary_color,
    size = 3,
    alpha = 0.6
  ) +
  # Add the prediction line
  geom_line(data = pred_data, aes(x = x, y = prob_nonzero), 
            color = accent_color, linewidth = 1.2) +
  # Add confidence ribbon (optional)
  geom_ribbon(
    data = pred_data,
    aes(x = x, 
        ymin = pmax(0, prob_nonzero - 0.05),  # approximate CI
        ymax = pmin(1, prob_nonzero + 0.05)),
    alpha = 0.2,
    fill = accent_color
  ) +
  labs(
    title = "A. Hurdle Component: Probability of Non-Zero",
    subtitle = "Points show binned proportions, line shows model predictions",
    x = "Predictor (x)", 
    y = "Probability of Roadkill Occurrence"
  ) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  theme_cohesive()

# Plot 2: Count component (conditional on non-zero)
p_sim2 <- sim_data %>%
  filter(y > 0) %>%
  ggplot() +
  geom_point(aes(x = x, y = y), color = primary_color, alpha = 0.4) +
  geom_line(data = pred_data, color = accent_color, aes(x = x, y = count_given_nonzero),
            color = "red", linewidth = 1) +
  labs(title = "B. Count Component: Intensity Given Presence",
       subtitle = "Line shows fitted hurdle model predictions",
       x = "Predictor (x)", y = "Count (y | y > 0)") +
  theme_cohesive()

p_sim1 + p_sim2
```

**Key Takeaway**: The simulation proves our modeling framework works—when we feed the hurdle model data generated from known parameters, it successfully recovers those parameters. This gives us confidence to apply it to real data where the true parameters are unknown.

------------------------------------------------------------------------

# 7. Results

### Fit Model to Real Data

```{r}
#| label: fit-model

# Full model with traffic, road characteristics, and land use
hurdle_model <- hurdle(
  roadkill_count ~ log_AADT + road_type + speed_limit +
                   pct_forest + pct_farmland + pct_residential + pct_park |
                   log_AADT + road_type + speed_limit +
                   pct_forest + pct_farmland + pct_residential + pct_park,
  data = model_data,
  offset = log(len_km),  # Controls for road length exposure
  dist = config$model_distribution,
  zero.dist = config$model_zero_dist
)
```

#### Model Diagnostics

> -   Log-Likelihood: `r round(logLik(hurdle_model), 1)`
> -   AIC: `r round(AIC(hurdle_model), 1)`
> -   BIC: `r round(BIC(hurdle_model), 1)`

### Model Coefficients

```{r}
#| label: results-table
#| echo: false

# Extract coefficients
coefs <- coef(hurdle_model)
se <- sqrt(diag(vcov(hurdle_model)))

results <- tibble(
  Parameter = names(coefs),
  Estimate = round(coefs, 4),
  SE = round(se, 4),
  Z_value = round(coefs/se, 2),
  P_value = round(2 * (1 - pnorm(abs(coefs/se))), 5)
) %>%
  mutate(Sig = case_when(
    P_value < 0.001 ~ "***",
    P_value < 0.01 ~ "**",
    P_value < 0.05 ~ "*",
    P_value < 0.1 ~ ".",
    TRUE ~ ""
  ))

knitr::kable(results, caption = "Hurdle Model Results")
```

#### Interpretation guide:

-   **Zero component**: Coefficients are log-odds. Positive → increases probability of roadkill occurring

-   **Count component**: Coefficients are on log scale. Positive → increases expected count given occurrence

-   **Significance**: \*\*\* p\<0.001, \*\* p\<0.01, \* p\<0.05

### Hypothesis Testing

```{r}
#| label: verify-results
#| echo: false
#| include: false

# Verify key results exist
if(!"zero_log_AADT" %in% results$Parameter) {
  stop("Missing zero_log_AADT in results")
}
```

```{r}
#| label: extract-key-results
#| echo: false

# Extract key coefficients for hypothesis tests
get_coef <- function(param_name) {
  results %>% filter(grepl(param_name, Parameter))
}

traffic_zero <- get_coef("zero_log_AADT")
traffic_count <- get_coef("count_log_AADT")
forest_zero <- get_coef("zero_pct_forest")
forest_count <- get_coef("count_pct_forest")
residential_zero <- get_coef("zero_pct_residential")
residential_count <- get_coef("count_pct_residential")
major_zero <- get_coef("zero_road_typeMajor")
major_count <- get_coef("count_road_typeMajor")
speed_zero <- get_coef("zero_speed_limit")
speed_count <- get_coef("count_speed_limit")
```

#### H1: Traffic Volume Effect

::::: columns
::: column
**Occurrence component:**

-   Coefficient: `r traffic_zero$Estimate`, SE: `r traffic_zero$SE`, p = `r traffic_zero$P_value` `r traffic_zero$Sig`

-   Result: Traffic `r ifelse(traffic_zero$P_value < 0.05, "significantly", "does not significantly")` affect `r ifelse(traffic_zero$P_value < 0.05, "s", "")` roadkill probability
:::

::: column
**Intensity component:**

-   Coefficient: `r traffic_count$Estimate`, SE: `r traffic_count$SE`, p = `r traffic_count$P_value` `r traffic_count$Sig`

-   Result: Traffic `r ifelse(traffic_count$P_value < 0.05, "significantly", "does not significantly")` affect `r ifelse(traffic_count$P_value < 0.05, "s", "")` collision intensity
:::
:::::

::::: columns
::: column
H1 Status: `r ifelse(traffic_zero$P_value < 0.05 | traffic_count$P_value < 0.05, "**SUPPORTED**", "**NOT SUPPORTED**")`
:::

::: column
**Effect size:** A 10% increase in traffic volume:

-   Changes odds of occurrence by `r round((exp(traffic_zero$Estimate * log(1.10)) - 1) * 100, 1)`%

-   Changes expected count by `r round((exp(traffic_count$Estimate * log(1.10)) - 1) * 100, 1)`%
:::
:::::

#### H2: Land Use Effects

::::: columns
::: column
##### H2a: Forest/Park habitat

Occurrence: p = `r forest_zero$P_value` `r forest_zero$Sig` \| Intensity: p = `r forest_count$P_value` `r forest_count$Sig`

Forest coverage `r ifelse(forest_zero$P_value < 0.05 | forest_count$P_value < 0.05, "significantly affects", "does not significantly affect")` roadkill patterns.
:::

::: column
##### H2b: Residential development

Occurrence: p = `r residential_zero$P_value` `r residential_zero$Sig` \| Intensity: p = `r residential_count$P_value` `r residential_count$Sig`

Residential areas show `r ifelse(residential_zero$Estimate < 0, "negative", "positive")` association (as predicted).
:::

H2 Status: `r ifelse((forest_zero$P_value < 0.05 | forest_count$P_value < 0.05) & (residential_zero$P_value < 0.05 | residential_count$P_value < 0.05), "**SUPPORTED**", "PARTIALLY SUPPORTED")`
:::::

#### H3: Road Characteristics

::::: columns
::: column
##### H3a: Major roads

Occurrence: p = `r major_zero$P_value` `r major_zero$Sig` \| Intensity: p = `r major_count$P_value` `r major_count$Sig`

Major roads have `r ifelse(major_zero$Estimate > 0, "higher", "lower")` roadkill rates than minor roads.
:::

::: column
##### H3b: Speed limit

Occurrence: p = `r speed_zero$P_value` `r speed_zero$Sig` \| Intensity: p = `r speed_count$P_value` `r speed_count$Sig`

Speed limit `r ifelse(speed_zero$P_value < 0.05 | speed_count$P_value < 0.05, "significantly", "does not significantly")` affect `r ifelse(speed_zero$P_value < 0.05 | speed_count$P_value < 0.05, "s", "")` collision risk.
:::

H3 Status: `r ifelse((major_zero$P_value < 0.05 | major_count$P_value < 0.05) & (speed_zero$P_value < 0.05 | speed_count$P_value < 0.05), "**SUPPORTED**", "PARTIALLY SUPPORTED")`
:::::

------------------------------------------------------------------------

# 8. Discussion

### Summary of Findings

```{r}
#| echo: false

summary_table <- tibble(
  Hypothesis = c("H1: Traffic", "H2a: Forest", "H2b: Residential", "H3a: Major roads", "H3b: Speed"),
  Occurrence = c(
    ifelse(traffic_zero$P_value < 0.05, ifelse(traffic_zero$Estimate > 0, "+", "−"), "NS"),
    ifelse(forest_zero$P_value < 0.05, ifelse(forest_zero$Estimate > 0, "+", "−"), "NS"),
    ifelse(residential_zero$P_value < 0.05, ifelse(residential_zero$Estimate > 0, "+", "−"), "NS"),
    ifelse(major_zero$P_value < 0.05, ifelse(major_zero$Estimate > 0, "+", "−"), "NS"),
    ifelse(speed_zero$P_value < 0.05, ifelse(speed_zero$Estimate > 0, "+", "−"), "NS")
  ),
  Intensity = c(
    ifelse(traffic_count$P_value < 0.05, ifelse(traffic_count$Estimate > 0, "+", "−"), "NS"),
    ifelse(forest_count$P_value < 0.05, ifelse(forest_count$Estimate > 0, "+", "−"), "NS"),
    ifelse(residential_count$P_value < 0.05, ifelse(residential_count$Estimate > 0, "+", "−"), "NS"),
    ifelse(major_count$P_value < 0.05, ifelse(major_count$Estimate > 0, "+", "−"), "NS"),
    ifelse(speed_count$P_value < 0.05, ifelse(speed_count$Estimate > 0, "+", "−"), "NS")
  ),
  Support = c(
    ifelse(traffic_zero$P_value < 0.05 | traffic_count$P_value < 0.05, "✓", "✗"),
    ifelse(forest_zero$P_value < 0.05 | forest_count$P_value < 0.05, "✓", "✗"),
    ifelse(residential_zero$P_value < 0.05 | residential_count$P_value < 0.05, "✓", "✗"),
    ifelse(major_zero$P_value < 0.05 | major_count$P_value < 0.05, "✓", "✗"),
    ifelse(speed_zero$P_value < 0.05 | speed_count$P_value < 0.05, "✓", "✗")
  )
)

knitr::kable(summary_table, caption = "Hypothesis Test Results (+ positive effect, − negative effect, NS not significant)")
```

### Policy Implications

Our findings suggest several evidence-based mitigation strategies:

1.  **Traffic management**: Roads with AADT \> `r format(quantile(model_data$AADT, 0.75, na.rm = TRUE), big.mark = ",")` vehicles/day (75th percentile) near natural habitats are high-priority for wildlife warning systems

2.  **Targeted interventions**: Focus mitigation efforts (wildlife crossings, fencing) on:

-   High-traffic corridors adjacent to forests/parks

-   Major highways with speed limits ≥80 km/h

-   Areas where predicted collision probability exceeds threshold

3.  **Land use planning**: Consider roadkill risk when approving development near wildlife habitat

### Limitations

1.  **Spatial coverage.** The analysis includes only roads near traffic counters (about 75% of the network). Low-traffic and rural roads may be underrepresented.

2.  **Species grouping.** All species are combined into one outcome. This hides differences in behavior and risk between species.

3.  **Timing differences across datasets.** Road data are from 2024, traffic data from 2019, and crash records from 2017–2019. Seasonal and daily patterns are not modeled, and these timing differences may add error.

4.  **Missing variables.** The model does not include direct data on animal population size, movement, road features (such as fencing and lighting), or driver behavior. These factors could affect collision risk and may influence the results.

5.  **Reporting bias.** Not all collisions are reported, and reporting likely differs by location. Rural areas in particular may appear safer simply because fewer events are recorded.

6.  **Spatial clustering.** Collisions tend to cluster in certain areas, but this spatial pattern is not explicitly modeled. This may lead to uncertainty being understated.

7.  **Interpretation.** Results show associations, not cause-and-effect. Land use is used as a stand-in for animal presence, and traffic estimates are imperfect.

#### Conclusions

This analysis demonstrates how hurdle models handle zero-inflated ecological count data by separately modeling occurrence and intensity processes. We identified traffic volume, land use composition, and road characteristics as key predictors of wildlife-vehicle collisions on Danish roads.

Key contributions:

-   Methodological framework for zero-inflated spatial count data

-   Quantified effects of infrastructure and landscape on roadkill risk

-   Policy-relevant findings for targeted mitigation

The hurdle model approach extends beyond roadkill to any ecological phenomenon with excess zeros: rare species observations, disease outbreaks, extreme weather events, or pollution violations.

------------------------------------------------------------------------

## References

::: {#refs}
:::
